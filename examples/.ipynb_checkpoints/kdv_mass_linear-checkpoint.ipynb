{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the base path\n",
    "weights_path = 'results/kdv/weights_sinpiu'\n",
    "data_path = 'results/kdv/data_sinpiu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import solve_ivp\n",
    "from scipy.fftpack import diff as psdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from koopmanlib.kdv_functions import *\n",
    "from koopmanlib.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the size of the domain, and create the discretized grid.\n",
    "L = 2 * np.pi\n",
    "Nx = 128\n",
    "dx = L / (Nx - 1.0)\n",
    "x = np.linspace(-np.pi, np.pi, Nx)\n",
    "\n",
    "# Set the initial conditions.\n",
    "y0 = kdv_exact(x, seed=123) \n",
    "\n",
    "# inner loop\n",
    "# # Set the time sample grid.\n",
    "# dt = 0.4 / (Nx**2)\n",
    "T = 0.01\n",
    "# Nt = int(T / dt)\n",
    "# dt = T / Nt\n",
    "# t = np.linspace(0, T, Nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049473900056532176"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_func(x, c):\n",
    "    return np.exp(-25 * (x - c)**2)\n",
    "\n",
    "c1, c2, c3 = -np.pi/2, 0, np.pi/2\n",
    "v1 = v_func(x, c1).reshape(1,-1)\n",
    "v2 = v_func(x, c2).reshape(1,-1)\n",
    "v3 = v_func(x, c3).reshape(1,-1)\n",
    "\n",
    "v_list = np.concatenate([v1,v2,v3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "umax = 1\n",
    "umin = -umax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dim = Nx\n",
    "param_dim = 3\n",
    "# n_init = 1000\n",
    "# traj_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traj_len = 500\n",
    "\n",
    "# n_init = 100\n",
    "\n",
    "# seed_IC = np.random.randint(0,100,size=(n_init,))\n",
    "# seed_IC\n",
    "\n",
    "# y0_list = []\n",
    "# for seed in seed_IC:\n",
    "#     y0 = kdv_exact(x, seed)\n",
    "#     y0_list.append(y0)\n",
    "# y0_list = np.asarray(y0_list)\n",
    "\n",
    "# y0_list.shape\n",
    "\n",
    "# param_list_group = np.random.uniform(low=0, high=1, size=(n_init, traj_len, param_dim)) * (umax - umin) + umin\n",
    "\n",
    "# soln_outer_list = []\n",
    "# for y0, param_list in zip(y0_list, param_list_group):\n",
    "#     # Calculate inner solution for each y0 and param_list (for one trajectory)\n",
    "#     soln_inner_list = [y0]\n",
    "#     for param in param_list:\n",
    "#         # Solve the equation using the scipy integrator\n",
    "#         soln = kdv_solution(y0, t, L, param, v_list)\n",
    "#         y0 = soln[-1]\n",
    "#         soln_inner_list.append(y0)\n",
    "\n",
    "#     soln_inner_list = np.asarray(soln_inner_list)\n",
    "    \n",
    "#     soln_outer_list.append(soln_inner_list)\n",
    "    \n",
    "# soln_outer_list = np.asarray(soln_outer_list)\n",
    "\n",
    "# soln_outer_list.shape\n",
    "\n",
    "# param_list_group.shape\n",
    "\n",
    "# data_x = soln_outer_list[:,:-1,:].reshape(-1, target_dim)\n",
    "# data_y = soln_outer_list[:,1:,:].reshape(-1, target_dim)\n",
    "# data_u = param_list_group.reshape(-1,param_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the array to a CSV file\n",
    "# np.savetxt('results/kdv/data/kdv_data_x.csv', data_x, delimiter=',')\n",
    "# np.savetxt('results/kdv/data/kdv_data_y.csv', data_y, delimiter=',')\n",
    "# np.savetxt('results/kdv/data/kdv_data_u.csv', data_u, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the CSV file\n",
    "# data_x = np.loadtxt('results/kdv/data/kdv_data_x_500.csv', delimiter=',')\n",
    "# data_y = np.loadtxt('results/kdv/data/kdv_data_y_500.csv', delimiter=',')\n",
    "# data_u = np.loadtxt('results/kdv/data/kdv_data_u_500.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data\n"
     ]
    }
   ],
   "source": [
    "print('load data')\n",
    "X = pd.read_csv(os.path.join(data_path,'kdv_X.csv'), header=None)\n",
    "Y = pd.read_csv(os.path.join(data_path,'kdv_Y.csv'), header=None)\n",
    "U = pd.read_csv(os.path.join(data_path,'kdv_U.csv'), header=None)\n",
    "\n",
    "data_x = X.values.T\n",
    "data_y = Y.values.T\n",
    "data_u = U.values.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from koopmanlib.dictionary import PsiNN, PsiNN_mass\n",
    "from koopmanlib.param_solver import KoopmanParametricDLSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from koopmanlib.param_solver import KoopmanLinearDLSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_psi_train = 2\n",
    "n_psi = 1 + 1 + n_psi_train # constant + momentum + mean + NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_linear = PsiNN_mass(layer_sizes=[16,16], n_psi_train=n_psi_train, dx=dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_linear = KoopmanLinearDLSolver(dic=dic_linear, target_dim=target_dim, param_dim=param_dim, n_psi=n_psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear = solver_linear.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_data_y_train = tf.zeros_like(dic_linear(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 3s 2ms/step - loss: 1.1926e-04 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3666e-05 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.7344e-05 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4569e-05 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3156e-05 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2401e-05 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1962e-05 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1701e-05 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1537e-05 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.1429e-05 - lr: 1.0000e-04\n",
      "number of the outer loop: 0\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.8228e-06 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.7352e-06 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.6840e-06 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.6482e-06 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.6230e-06 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.6050e-06 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.5925e-06 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.5831e-06 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.5753e-06 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.5698e-06 - lr: 1.0000e-04\n",
      "number of the outer loop: 1\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.4540e-06 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.4465e-06 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.4431e-06 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.4406e-06 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.4384e-06 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.4364e-06 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.4350e-06 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.4338e-06 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.4324e-06 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.4312e-06 - lr: 1.0000e-04\n",
      "number of the outer loop: 2\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3878e-06 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3857e-06 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3850e-06 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3842e-06 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3837e-06 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3830e-06 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3823e-06 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3818e-06 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3813e-06 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3807e-06 - lr: 1.0000e-04\n",
      "number of the outer loop: 3\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3567e-06 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3559e-06 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3554e-06 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3551e-06 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3545e-06 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3542e-06 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3544e-06 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3543e-06 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3538e-06 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3536e-06 - lr: 1.0000e-04\n",
      "number of the outer loop: 4\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3343e-06 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3331e-06 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3335e-06 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3330e-06 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3327e-06 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3324e-06 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3324e-06 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3320e-06 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3318e-06 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3317e-06 - lr: 1.0000e-04\n",
      "number of the outer loop: 5\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3118e-06 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3116e-06 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3110e-06 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3110e-06 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3111e-06 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3108e-06 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3106e-06 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3107e-06 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3104e-06 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.3102e-06 - lr: 1.0000e-04\n",
      "number of the outer loop: 6\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.2866e-06 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2862e-06 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2860e-06 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2856e-06 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2856e-06 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2855e-06 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.2854e-06 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2852e-06 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2851e-06 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2848e-06 - lr: 1.0000e-04\n",
      "number of the outer loop: 7\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2625e-06 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2621e-06 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2618e-06 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2619e-06 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2617e-06 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2616e-06 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2615e-06 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2613e-06 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2611e-06 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2614e-06 - lr: 1.0000e-04\n",
      "number of the outer loop: 8\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2380e-06 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2376e-06 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2376e-06 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2377e-06 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2374e-06 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2373e-06 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2372e-06 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2371e-06 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2372e-06 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2370e-06 - lr: 1.0000e-04\n",
      "number of the outer loop: 9\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2168e-06 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2165e-06 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2160e-06 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2161e-06 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2163e-06 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2159e-06 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2161e-06 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.2158e-06 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.2160e-06 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.2160e-06 - lr: 1.0000e-04\n",
      "number of the outer loop: 10\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1972e-06 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1967e-06 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1967e-06 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1966e-06 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1966e-06 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1968e-06 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1966e-06 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1965e-06 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1967e-06 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1963e-06 - lr: 1.0000e-04\n",
      "number of the outer loop: 11\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1810e-06 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1804e-06 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1803e-06 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1803e-06 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1803e-06 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1805e-06 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1803e-06 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1803e-06 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1803e-06 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1799e-06 - lr: 1.0000e-04\n",
      "number of the outer loop: 12\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1669e-06 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1666e-06 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1665e-06 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1664e-06 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1663e-06 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1665e-06 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1664e-06 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1662e-06 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1662e-06 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1663e-06 - lr: 1.0000e-04\n",
      "number of the outer loop: 13\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1550e-06 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1547e-06 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1547e-06 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1546e-06 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1547e-06 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1546e-06 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1545e-06 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1547e-06 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1545e-06 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1546e-06 - lr: 1.0000e-04\n",
      "number of the outer loop: 14\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1426e-06 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1424e-06 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1423e-06 - lr: 1.0000e-04\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1422e-06 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1422e-06 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1423e-06 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1420e-06 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1421e-06 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1420e-06 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1420e-06 - lr: 1.0000e-04\n",
      "number of the outer loop: 15\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1304e-06 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1300e-06 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1299e-06 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1299e-06 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1300e-06 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1297e-06 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1298e-06 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1298e-06 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1296e-06 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1296e-06 - lr: 1.0000e-04\n",
      "number of the outer loop: 16\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1172e-06 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1168e-06 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1168e-06 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1167e-06 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1166e-06 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1166e-06 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1166e-06 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1164e-06 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1164e-06 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1164e-06 - lr: 1.0000e-04\n",
      "number of the outer loop: 17\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1027e-06 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1020e-06 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1019e-06 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1020e-06 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1019e-06 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1020e-06 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1017e-06 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1018e-06 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1017e-06 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.1018e-06 - lr: 1.0000e-04\n",
      "number of the outer loop: 18\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.0874e-06 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.0867e-06 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.0868e-06 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.0867e-06 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.0868e-06 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.0865e-06 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.0865e-06 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.0865e-06 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.0863e-06 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0863e-06 - lr: 1.0000e-04\n",
      "number of the outer loop: 19\n"
     ]
    }
   ],
   "source": [
    "solver_linear.build(model_linear,\n",
    "                    data_x,\n",
    "                    data_u, \n",
    "                    data_y, \n",
    "                    zeros_data_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=200,\n",
    "                    lr=1e-4,\n",
    "                    log_interval=20,\n",
    "                    lr_decay_factor=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_linear.model.save_weights(os.path.join(weights_path, 'linear_kdv_mass_weights_psi2.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver_linear.model.load_weights(os.path.join(weights_path, 'linear_kdv_mass_weights_psi2.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_linear_obs(y0, param_list, B_obs):\n",
    "    param_list = tf.reshape(param_list, shape=(param_list.shape[0], 1, param_dim))\n",
    "    y0 = y0.reshape(1,-1)\n",
    "    psi_y = solver_linear.dic.call(y0)\n",
    "    obs_list = [psi_y@B_obs]\n",
    "    \n",
    "    for param in param_list:\n",
    "        psi_y = solver_linear.model.get_layer('Layer_A')(psi_y) + solver_linear.model.get_layer('Layer_B')(param)\n",
    "        obs_next = psi_y@B_obs\n",
    "        obs_list.append(obs_next)\n",
    "        \n",
    "    return np.squeeze(np.asarray(obs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kdv_soln(y0, param_list):\n",
    "    y0_loop = y0\n",
    "    kdv_soln_list = [y0_loop]\n",
    "    for param in param_list:\n",
    "        # Solve the equation using the scipy integrator\n",
    "        soln = kdv_solution(y0_loop, T, L, param, v_list,x)\n",
    "        y0_loop = soln.y.T[-1]\n",
    "        kdv_soln_list.append(y0_loop)\n",
    "    return kdv_soln_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_traj_number = 5\n",
    "np.random.seed(1)\n",
    "seed_list = np.random.randint(low=1, high=200, size=(pred_traj_number,2))\n",
    "\n",
    "y0_pred_list=[]\n",
    "param_pred_list = []\n",
    "\n",
    "Tsim_pred = 0.1\n",
    "traj_len_pred = int(Tsim_pred / T)\n",
    "\n",
    "for seed_x, seed_u in seed_list:\n",
    "    # Forward prediction problem setting\n",
    "    y0_pred = kdv_exact(x, seed=seed_x) \n",
    "    \n",
    "\n",
    "    # Set the seed of param_list\n",
    "    np.random.seed(seed_u)\n",
    "\n",
    "    param_pred = np.random.uniform(low=0, high=1, size=(traj_len_pred, param_dim)) * (umax - umin) + umin\n",
    "    \n",
    "    y0_pred_list.append(y0_pred)\n",
    "    param_pred_list.append(param_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list_linear = compute_error(dic=dic_linear,\n",
    "                           compute_kdv_soln_func=compute_kdv_soln,\n",
    "                           compute_obs_func_model=compute_linear_obs,\n",
    "                           error_func=compute_diff_ratio_one_traj,\n",
    "                           y0_pred_list=y0_pred_list,\n",
    "                           param_pred_list=param_pred_list,\n",
    "                           dx=dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_linear, std_linear, mean_plus_linear, mean_minus_linear = compute_stat_info(error_list_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 11)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_list_linear.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00052441, 0.00377252, 0.00370028, 0.00462437,\n",
       "       0.00556003, 0.00693941, 0.00649797, 0.00704854, 0.00746011,\n",
       "       0.0080974 ])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(error_list_linear, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_error_linear = {'mean': mean_linear,\n",
    "             'std': std_linear,\n",
    "             'mean_plus':mean_plus_linear,\n",
    "             'mean_minus':mean_minus_linear}\n",
    "# np.save(os.path.join(data_path,'error_linear.npy'), dict_error_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x7fcb51b5ad00>"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_axis = np.arange(0, traj_len_pred+1, 1)\n",
    "\n",
    "plt.plot(mean_linear, label='P-Koopman', color='steelblue', linewidth=3)\n",
    "plt.fill_between(t_axis, np.maximum(mean_minus_linear,0), mean_plus_linear, color='lightsteelblue', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing reference\n",
    "\n",
    "# y0_track = np.zeros(shape=(Nx, )) + 0.2\n",
    "\n",
    "# Tpred_track = 0.02\n",
    "# Tsim_track = 20\n",
    "\n",
    "# traj_len_track = int(Tsim_track / T)\n",
    "# Np = int(Tpred_track / T)\n",
    "\n",
    "# ### Set piece-wise reference\n",
    "# soln_ref = np.zeros(shape=(traj_len_track+Np, target_dim))+0.3\n",
    "\n",
    "# for i in range(soln_ref.shape[0]):\n",
    "#     if i > traj_len_track / 2:\n",
    "#         soln_ref[i, :] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing reference\n",
    "y0_track = np.zeros(shape=(Nx, )) + 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y0_track = kdv_exact(x, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tpred_track = 0.02\n",
    "Tsim_track = 20\n",
    "\n",
    "traj_len_track = int(Tsim_track / T)\n",
    "Np = int(Tpred_track / T)\n",
    "\n",
    "### Set piece-wise reference\n",
    "soln_ref = np.zeros(shape=(traj_len_track+Np, target_dim))+0.3\n",
    "\n",
    "for i in range(soln_ref.shape[0]):\n",
    "    if i > traj_len_track / 2:\n",
    "        soln_ref[i, :] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = Np-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soln_ref = np.loadtxt(os.path.join(data_path,'track_soln_ref'), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('results/kdv/data_nonlinear/track_soln_ref', soln_ref, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_ref = dx * tf.reshape(tf.math.reduce_sum(soln_ref, axis=-1), shape=(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2002, 1), dtype=float64, numpy=\n",
       "array([[1.89979776],\n",
       "       [1.89979776],\n",
       "       [1.89979776],\n",
       "       ...,\n",
       "       [3.1663296 ],\n",
       "       [3.1663296 ],\n",
       "       [3.1663296 ]])>"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpc_loss_linear(param, tau, ref_list, y0, B):\n",
    "    param = tf.reshape(param, shape=(int(param.shape[0]/param_dim), 1, param_dim))\n",
    "    loss_list = []\n",
    "    y0 = y0.reshape(1,-1)\n",
    "    psi_y = solver_linear.dic.call(y0)\n",
    "    \n",
    "    for i in range(tau):\n",
    "        psi_y = solver_linear.model.get_layer('Layer_A')(psi_y) + solver_linear.model.get_layer('Layer_B')(param[i])\n",
    "        obs = psi_y@B\n",
    "        loss_curr = tf.square(tf.norm(ref_list[i] - obs))\n",
    "        loss_list.append(loss_curr)\n",
    "    \n",
    "    ref_loss= tf.reduce_sum(loss_list)\n",
    "    param_loss = 0 * tf.reduce_sum(tf.square(tf.norm(param, axis=-1)))\n",
    "    \n",
    "    loss = ref_loss + param_loss\n",
    "    \n",
    "#     loss = ref_loss\n",
    "    return loss   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KoopmanMPC(y0, traj_len, soln_ref, kdv_solver, B, loss):\n",
    "    \n",
    "    bounds= []\n",
    "    for i in range(tau*param_dim):\n",
    "        bounds.append((-1,1))\n",
    "\n",
    "    y0_mpc_loop_list = [y0]\n",
    "    opt_control_list = []\n",
    "    for current_time in range(traj_len):\n",
    "        print('current time step: ', current_time)\n",
    "        start_time = time.time()\n",
    "        # This needs param_init is a scalor\n",
    "\n",
    "        param_init = np.random.uniform(low=0, high=1, size=(tau * param_dim, )) * (umax - umin) + umin\n",
    "#         param_init = np.zeros(shape=(tau * param_dim, ))+0.001\n",
    " \n",
    "        results = minimize(loss, \n",
    "                       x0=param_init,\n",
    "                       args = (tau, soln_ref[current_time+1:current_time+1+tau,:], y0_mpc_loop_list[-1], B),\n",
    "                       bounds=bounds)\n",
    "\n",
    "        param = results.x.reshape(tau, param_dim)[0]\n",
    "        soln_next = kdv_solver(y0_mpc_loop_list[-1], T, L, param, v_list,x)\n",
    "        y_next = soln_next.y.T[-1]\n",
    "        y0_mpc_loop_list.append(y_next)\n",
    "        opt_control_list.append(param)\n",
    "        end_time = time.time()\n",
    "\n",
    "        print('loss: ', results.fun)\n",
    "        \n",
    "    opt_control_list = np.asarray(opt_control_list)\n",
    "    y0_mpc_loop_list = np.asarray(y0_mpc_loop_list)\n",
    "    \n",
    "    return opt_control_list, y0_mpc_loop_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current time step:  0\n",
      "loss:  0.38827897237132575\n",
      "current time step:  1\n",
      "loss:  0.38827897237132575\n",
      "current time step:  2\n",
      "loss:  0.38827897237132575\n",
      "current time step:  3\n",
      "loss:  0.38827897237132575\n",
      "current time step:  4\n",
      "loss:  0.38827897237132575\n",
      "current time step:  5\n",
      "loss:  0.38827897237132575\n",
      "current time step:  6\n",
      "loss:  0.38827897237132575\n",
      "current time step:  7\n",
      "loss:  0.38827897237132575\n",
      "current time step:  8\n",
      "loss:  0.38827897237132575\n",
      "current time step:  9\n",
      "loss:  0.38827897237132575\n",
      "current time step:  10\n",
      "loss:  0.38827897237132575\n",
      "current time step:  11\n",
      "loss:  0.38827897237132575\n",
      "current time step:  12\n",
      "loss:  0.38827897237132575\n",
      "current time step:  13\n",
      "loss:  0.38827897237132575\n",
      "current time step:  14\n",
      "loss:  0.38827897237132575\n",
      "current time step:  15\n",
      "loss:  0.38827897237132575\n",
      "current time step:  16\n",
      "loss:  0.38827897237132575\n",
      "current time step:  17\n",
      "loss:  0.38827897237132575\n",
      "current time step:  18\n",
      "loss:  0.38827897237132575\n",
      "current time step:  19\n",
      "loss:  0.38827897237132575\n",
      "current time step:  20\n",
      "loss:  0.38827897237132575\n",
      "current time step:  21\n",
      "loss:  0.38827897237132575\n",
      "current time step:  22\n",
      "loss:  0.38827897237132575\n",
      "current time step:  23\n",
      "loss:  0.38827897237132575\n",
      "current time step:  24\n",
      "loss:  0.38827897237132575\n",
      "current time step:  25\n",
      "loss:  0.38827897237132575\n",
      "current time step:  26\n",
      "loss:  0.38827897237132575\n",
      "current time step:  27\n",
      "loss:  0.38827897237132575\n",
      "current time step:  28\n",
      "loss:  0.38827897237132575\n",
      "current time step:  29\n",
      "loss:  0.38827897237132575\n",
      "current time step:  30\n",
      "loss:  0.38827897237132575\n",
      "current time step:  31\n",
      "loss:  0.38827897237132575\n",
      "current time step:  32\n",
      "loss:  0.38827897237132575\n",
      "current time step:  33\n",
      "loss:  0.38827897237132575\n",
      "current time step:  34\n",
      "loss:  0.38827897237132575\n",
      "current time step:  35\n",
      "loss:  0.38827897237132575\n",
      "current time step:  36\n",
      "loss:  0.38827897237132575\n",
      "current time step:  37\n",
      "loss:  0.38827897237132575\n",
      "current time step:  38\n",
      "loss:  0.38827897237132575\n",
      "current time step:  39\n",
      "loss:  0.38827897237132575\n",
      "current time step:  40\n",
      "loss:  0.38827897237132575\n",
      "current time step:  41\n",
      "loss:  0.38827897237132575\n",
      "current time step:  42\n",
      "loss:  0.38827897237132575\n",
      "current time step:  43\n",
      "loss:  0.38827897237132575\n",
      "current time step:  44\n",
      "loss:  0.38827897237132575\n",
      "current time step:  45\n",
      "loss:  0.38827897237132575\n",
      "current time step:  46\n",
      "loss:  0.38827897237132575\n",
      "current time step:  47\n",
      "loss:  0.38827897237132575\n",
      "current time step:  48\n",
      "loss:  0.38827897237132575\n",
      "current time step:  49\n",
      "loss:  0.38827897237132575\n",
      "current time step:  50\n",
      "loss:  0.38827897237132575\n",
      "current time step:  51\n",
      "loss:  0.38827897237132575\n",
      "current time step:  52\n",
      "loss:  0.38827897237132575\n",
      "current time step:  53\n",
      "loss:  0.38827897237132575\n",
      "current time step:  54\n",
      "loss:  0.38827897237132575\n",
      "current time step:  55\n",
      "loss:  0.38827897237132575\n",
      "current time step:  56\n",
      "loss:  0.38827897237132575\n",
      "current time step:  57\n",
      "loss:  0.38827897237132575\n",
      "current time step:  58\n",
      "loss:  0.38827897237132575\n",
      "current time step:  59\n",
      "loss:  0.38827897237132575\n",
      "current time step:  60\n",
      "loss:  0.38827897237132575\n",
      "current time step:  61\n",
      "loss:  0.38827897237132575\n",
      "current time step:  62\n",
      "loss:  0.38827897237132575\n",
      "current time step:  63\n",
      "loss:  0.38827897237132575\n",
      "current time step:  64\n",
      "loss:  0.38827897237132575\n",
      "current time step:  65\n",
      "loss:  0.38827897237132575\n",
      "current time step:  66\n",
      "loss:  0.38827897237132575\n",
      "current time step:  67\n",
      "loss:  0.38827897237132575\n",
      "current time step:  68\n",
      "loss:  0.38827897237132575\n",
      "current time step:  69\n",
      "loss:  0.38827897237132575\n",
      "current time step:  70\n",
      "loss:  0.38827897237132575\n",
      "current time step:  71\n",
      "loss:  0.38827897237132575\n",
      "current time step:  72\n",
      "loss:  0.38827897237132575\n",
      "current time step:  73\n",
      "loss:  0.38827897237132575\n",
      "current time step:  74\n",
      "loss:  0.38827897237132575\n",
      "current time step:  75\n",
      "loss:  0.38827897237132575\n",
      "current time step:  76\n",
      "loss:  0.38827897237132575\n",
      "current time step:  77\n",
      "loss:  0.38827897237132575\n",
      "current time step:  78\n",
      "loss:  0.38827897237132575\n",
      "current time step:  79\n",
      "loss:  0.38827897237132575\n",
      "current time step:  80\n",
      "loss:  0.38827897237132575\n",
      "current time step:  81\n",
      "loss:  0.38827897237132575\n",
      "current time step:  82\n",
      "loss:  0.38827897237132575\n",
      "current time step:  83\n",
      "loss:  0.38827897237132575\n",
      "current time step:  84\n",
      "loss:  0.38827897237132575\n",
      "current time step:  85\n",
      "loss:  0.38827897237132575\n",
      "current time step:  86\n",
      "loss:  0.38827897237132575\n",
      "current time step:  87\n",
      "loss:  0.38827897237132575\n",
      "current time step:  88\n",
      "loss:  0.38827897237132575\n",
      "current time step:  89\n",
      "loss:  0.38827897237132575\n",
      "current time step:  90\n",
      "loss:  0.38827897237132575\n",
      "current time step:  91\n",
      "loss:  0.38827897237132575\n",
      "current time step:  92\n",
      "loss:  0.38827897237132575\n",
      "current time step:  93\n",
      "loss:  0.38827897237132575\n",
      "current time step:  94\n",
      "loss:  0.38827897237132575\n",
      "current time step:  95\n",
      "loss:  0.38827897237132575\n",
      "current time step:  96\n",
      "loss:  0.38827897237132575\n",
      "current time step:  97\n",
      "loss:  0.38827897237132575\n",
      "current time step:  98\n",
      "loss:  0.38827897237132575\n",
      "current time step:  99\n",
      "loss:  0.38827897237132575\n",
      "current time step:  100\n",
      "loss:  0.38827897237132575\n",
      "current time step:  101\n",
      "loss:  0.38827897237132575\n",
      "current time step:  102\n",
      "loss:  0.38827897237132575\n",
      "current time step:  103\n",
      "loss:  0.38827897237132575\n",
      "current time step:  104\n",
      "loss:  0.38827897237132575\n",
      "current time step:  105\n",
      "loss:  0.38827897237132575\n",
      "current time step:  106\n",
      "loss:  0.38827897237132575\n",
      "current time step:  107\n",
      "loss:  0.38827897237132575\n",
      "current time step:  108\n",
      "loss:  0.38827897237132575\n",
      "current time step:  109\n",
      "loss:  0.38827897237132575\n",
      "current time step:  110\n",
      "loss:  0.38827897237132575\n",
      "current time step:  111\n",
      "loss:  0.38827897237132575\n",
      "current time step:  112\n",
      "loss:  0.38827897237132575\n",
      "current time step:  113\n",
      "loss:  0.38827897237132575\n",
      "current time step:  114\n",
      "loss:  0.38827897237132575\n",
      "current time step:  115\n",
      "loss:  0.38827897237132575\n",
      "current time step:  116\n",
      "loss:  0.38827897237132575\n",
      "current time step:  117\n",
      "loss:  0.38827897237132575\n",
      "current time step:  118\n",
      "loss:  0.38827897237132575\n",
      "current time step:  119\n",
      "loss:  0.38827897237132575\n",
      "current time step:  120\n",
      "loss:  0.38827897237132575\n",
      "current time step:  121\n",
      "loss:  0.38827897237132575\n",
      "current time step:  122\n",
      "loss:  0.38827897237132575\n",
      "current time step:  123\n",
      "loss:  0.38827897237132575\n",
      "current time step:  124\n",
      "loss:  0.38827897237132575\n",
      "current time step:  125\n",
      "loss:  0.38827897237132575\n",
      "current time step:  126\n",
      "loss:  0.38827897237132575\n",
      "current time step:  127\n",
      "loss:  0.38827897237132575\n",
      "current time step:  128\n",
      "loss:  0.38827897237132575\n",
      "current time step:  129\n",
      "loss:  0.38827897237132575\n",
      "current time step:  130\n",
      "loss:  0.38827897237132575\n",
      "current time step:  131\n",
      "loss:  0.38827897237132575\n",
      "current time step:  132\n",
      "loss:  0.38827897237132575\n",
      "current time step:  133\n",
      "loss:  0.38827897237132575\n",
      "current time step:  134\n",
      "loss:  0.38827897237132575\n",
      "current time step:  135\n",
      "loss:  0.38827897237132575\n",
      "current time step:  136\n",
      "loss:  0.38827897237132575\n",
      "current time step:  137\n",
      "loss:  0.38827897237132575\n",
      "current time step:  138\n",
      "loss:  0.38827897237132575\n",
      "current time step:  139\n",
      "loss:  0.38827897237132575\n",
      "current time step:  140\n",
      "loss:  0.38827897237132575\n",
      "current time step:  141\n",
      "loss:  0.38827897237132575\n",
      "current time step:  142\n",
      "loss:  0.38827897237132575\n",
      "current time step:  143\n",
      "loss:  0.38827897237132575\n",
      "current time step:  144\n",
      "loss:  0.38827897237132575\n",
      "current time step:  145\n",
      "loss:  0.38827897237132575\n",
      "current time step:  146\n",
      "loss:  0.38827897237132575\n",
      "current time step:  147\n",
      "loss:  0.38827897237132575\n",
      "current time step:  148\n",
      "loss:  0.38827897237132575\n",
      "current time step:  149\n",
      "loss:  0.38827897237132575\n",
      "current time step:  150\n",
      "loss:  0.38827897237132575\n",
      "current time step:  151\n",
      "loss:  0.38827897237132575\n",
      "current time step:  152\n",
      "loss:  0.38827897237132575\n",
      "current time step:  153\n",
      "loss:  0.38827897237132575\n",
      "current time step:  154\n",
      "loss:  0.38827897237132575\n",
      "current time step:  155\n",
      "loss:  0.38827897237132575\n",
      "current time step:  156\n",
      "loss:  0.38827897237132575\n",
      "current time step:  157\n",
      "loss:  0.38827897237132575\n",
      "current time step:  158\n",
      "loss:  0.38827897237132575\n",
      "current time step:  159\n",
      "loss:  0.38827897237132575\n",
      "current time step:  160\n",
      "loss:  0.38827897237132575\n",
      "current time step:  161\n",
      "loss:  0.38827897237132575\n",
      "current time step:  162\n",
      "loss:  0.38827897237132575\n",
      "current time step:  163\n",
      "loss:  0.38827897237132575\n",
      "current time step:  164\n",
      "loss:  0.38827897237132575\n",
      "current time step:  165\n",
      "loss:  0.38827897237132575\n",
      "current time step:  166\n",
      "loss:  0.38827897237132575\n",
      "current time step:  167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.38827897237132575\n",
      "current time step:  168\n",
      "loss:  0.38827897237132575\n",
      "current time step:  169\n",
      "loss:  0.38827897237132575\n",
      "current time step:  170\n",
      "loss:  0.38827897237132575\n",
      "current time step:  171\n",
      "loss:  0.38827897237132575\n",
      "current time step:  172\n",
      "loss:  0.38827897237132575\n",
      "current time step:  173\n",
      "loss:  0.38827897237132575\n",
      "current time step:  174\n",
      "loss:  0.38827897237132575\n",
      "current time step:  175\n",
      "loss:  0.38827897237132575\n",
      "current time step:  176\n",
      "loss:  0.38827897237132575\n",
      "current time step:  177\n",
      "loss:  0.38827897237132575\n",
      "current time step:  178\n",
      "loss:  0.38827897237132575\n",
      "current time step:  179\n",
      "loss:  0.38827897237132575\n",
      "current time step:  180\n",
      "loss:  0.38827897237132575\n",
      "current time step:  181\n",
      "loss:  0.38827897237132575\n",
      "current time step:  182\n",
      "loss:  0.38827897237132575\n",
      "current time step:  183\n",
      "loss:  0.38827897237132575\n",
      "current time step:  184\n",
      "loss:  0.38827897237132575\n",
      "current time step:  185\n",
      "loss:  0.38827897237132575\n",
      "current time step:  186\n",
      "loss:  0.38827897237132575\n",
      "current time step:  187\n",
      "loss:  0.38827897237132575\n",
      "current time step:  188\n",
      "loss:  0.38827897237132575\n",
      "current time step:  189\n",
      "loss:  0.38827897237132575\n",
      "current time step:  190\n",
      "loss:  0.38827897237132575\n",
      "current time step:  191\n",
      "loss:  0.38827897237132575\n",
      "current time step:  192\n",
      "loss:  0.38827897237132575\n",
      "current time step:  193\n",
      "loss:  0.38827897237132575\n",
      "current time step:  194\n",
      "loss:  0.38827897237132575\n",
      "current time step:  195\n",
      "loss:  0.38827897237132575\n",
      "current time step:  196\n",
      "loss:  0.38827897237132575\n",
      "current time step:  197\n",
      "loss:  0.38827897237132575\n",
      "current time step:  198\n",
      "loss:  0.38827897237132575\n",
      "current time step:  199\n",
      "loss:  0.38827897237132575\n",
      "current time step:  200\n",
      "loss:  0.38827897237132575\n",
      "current time step:  201\n",
      "loss:  0.38827897237132575\n",
      "current time step:  202\n",
      "loss:  0.38827897237132575\n",
      "current time step:  203\n",
      "loss:  0.38827897237132575\n",
      "current time step:  204\n",
      "loss:  0.38827897237132575\n",
      "current time step:  205\n",
      "loss:  0.38827897237132575\n",
      "current time step:  206\n",
      "loss:  0.38827897237132575\n",
      "current time step:  207\n",
      "loss:  0.38827897237132575\n",
      "current time step:  208\n",
      "loss:  0.38827897237132575\n",
      "current time step:  209\n",
      "loss:  0.38827897237132575\n",
      "current time step:  210\n",
      "loss:  0.38827897237132575\n",
      "current time step:  211\n",
      "loss:  0.38827897237132575\n",
      "current time step:  212\n",
      "loss:  0.38827897237132575\n",
      "current time step:  213\n",
      "loss:  0.38827897237132575\n",
      "current time step:  214\n",
      "loss:  0.38827897237132575\n",
      "current time step:  215\n",
      "loss:  0.38827897237132575\n",
      "current time step:  216\n",
      "loss:  0.38827897237132575\n",
      "current time step:  217\n",
      "loss:  0.38827897237132575\n",
      "current time step:  218\n",
      "loss:  0.38827897237132575\n",
      "current time step:  219\n",
      "loss:  0.38827897237132575\n",
      "current time step:  220\n",
      "loss:  0.38827897237132575\n",
      "current time step:  221\n",
      "loss:  0.38827897237132575\n",
      "current time step:  222\n",
      "loss:  0.38827897237132575\n",
      "current time step:  223\n",
      "loss:  0.38827897237132575\n",
      "current time step:  224\n",
      "loss:  0.38827897237132575\n",
      "current time step:  225\n",
      "loss:  0.38827897237132575\n",
      "current time step:  226\n",
      "loss:  0.38827897237132575\n",
      "current time step:  227\n",
      "loss:  0.38827897237132575\n",
      "current time step:  228\n",
      "loss:  0.38827897237132575\n",
      "current time step:  229\n",
      "loss:  0.38827897237132575\n",
      "current time step:  230\n",
      "loss:  0.38827897237132575\n",
      "current time step:  231\n",
      "loss:  0.38827897237132575\n",
      "current time step:  232\n",
      "loss:  0.38827897237132575\n",
      "current time step:  233\n",
      "loss:  0.38827897237132575\n",
      "current time step:  234\n",
      "loss:  0.38827897237132575\n",
      "current time step:  235\n",
      "loss:  0.38827897237132575\n",
      "current time step:  236\n",
      "loss:  0.38827897237132575\n",
      "current time step:  237\n",
      "loss:  0.38827897237132575\n",
      "current time step:  238\n",
      "loss:  0.38827897237132575\n",
      "current time step:  239\n",
      "loss:  0.38827897237132575\n",
      "current time step:  240\n",
      "loss:  0.38827897237132575\n",
      "current time step:  241\n",
      "loss:  0.38827897237132575\n",
      "current time step:  242\n",
      "loss:  0.38827897237132575\n",
      "current time step:  243\n",
      "loss:  0.38827897237132575\n",
      "current time step:  244\n",
      "loss:  0.38827897237132575\n",
      "current time step:  245\n",
      "loss:  0.38827897237132575\n",
      "current time step:  246\n",
      "loss:  0.38827897237132575\n",
      "current time step:  247\n",
      "loss:  0.38827897237132575\n",
      "current time step:  248\n",
      "loss:  0.38827897237132575\n",
      "current time step:  249\n",
      "loss:  0.38827897237132575\n",
      "current time step:  250\n",
      "loss:  0.38827897237132575\n",
      "current time step:  251\n",
      "loss:  0.38827897237132575\n",
      "current time step:  252\n",
      "loss:  0.38827897237132575\n",
      "current time step:  253\n",
      "loss:  0.38827897237132575\n",
      "current time step:  254\n",
      "loss:  0.38827897237132575\n",
      "current time step:  255\n",
      "loss:  0.38827897237132575\n",
      "current time step:  256\n",
      "loss:  0.38827897237132575\n",
      "current time step:  257\n",
      "loss:  0.38827897237132575\n",
      "current time step:  258\n",
      "loss:  0.38827897237132575\n",
      "current time step:  259\n",
      "loss:  0.38827897237132575\n",
      "current time step:  260\n",
      "loss:  0.38827897237132575\n",
      "current time step:  261\n",
      "loss:  0.38827897237132575\n",
      "current time step:  262\n",
      "loss:  0.38827897237132575\n",
      "current time step:  263\n",
      "loss:  0.38827897237132575\n",
      "current time step:  264\n",
      "loss:  0.38827897237132575\n",
      "current time step:  265\n",
      "loss:  0.38827897237132575\n",
      "current time step:  266\n",
      "loss:  0.38827897237132575\n",
      "current time step:  267\n",
      "loss:  0.38827897237132575\n",
      "current time step:  268\n",
      "loss:  0.38827897237132575\n",
      "current time step:  269\n",
      "loss:  0.38827897237132575\n",
      "current time step:  270\n",
      "loss:  0.38827897237132575\n",
      "current time step:  271\n",
      "loss:  0.38827897237132575\n",
      "current time step:  272\n",
      "loss:  0.38827897237132575\n",
      "current time step:  273\n",
      "loss:  0.38827897237132575\n",
      "current time step:  274\n",
      "loss:  0.38827897237132575\n",
      "current time step:  275\n",
      "loss:  0.38827897237132575\n",
      "current time step:  276\n",
      "loss:  0.38827897237132575\n",
      "current time step:  277\n",
      "loss:  0.38827897237132575\n",
      "current time step:  278\n",
      "loss:  0.38827897237132575\n",
      "current time step:  279\n",
      "loss:  0.38827897237132575\n",
      "current time step:  280\n",
      "loss:  0.38827897237132575\n",
      "current time step:  281\n",
      "loss:  0.38827897237132575\n",
      "current time step:  282\n",
      "loss:  0.38827897237132575\n",
      "current time step:  283\n",
      "loss:  0.38827897237132575\n",
      "current time step:  284\n",
      "loss:  0.38827897237132575\n",
      "current time step:  285\n",
      "loss:  0.38827897237132575\n",
      "current time step:  286\n",
      "loss:  0.38827897237132575\n",
      "current time step:  287\n",
      "loss:  0.38827897237132575\n",
      "current time step:  288\n",
      "loss:  0.38827897237132575\n",
      "current time step:  289\n",
      "loss:  0.38827897237132575\n",
      "current time step:  290\n",
      "loss:  0.38827897237132575\n",
      "current time step:  291\n",
      "loss:  0.38827897237132575\n",
      "current time step:  292\n",
      "loss:  0.38827897237132575\n",
      "current time step:  293\n",
      "loss:  0.38827897237132575\n",
      "current time step:  294\n",
      "loss:  0.38827897237132575\n",
      "current time step:  295\n",
      "loss:  0.38827897237132575\n",
      "current time step:  296\n",
      "loss:  0.38827897237132575\n",
      "current time step:  297\n",
      "loss:  0.38827897237132575\n",
      "current time step:  298\n",
      "loss:  0.38827897237132575\n",
      "current time step:  299\n",
      "loss:  0.38827897237132575\n",
      "current time step:  300\n",
      "loss:  0.38827897237132575\n",
      "current time step:  301\n",
      "loss:  0.38827897237132575\n",
      "current time step:  302\n",
      "loss:  0.38827897237132575\n",
      "current time step:  303\n",
      "loss:  0.38827897237132575\n",
      "current time step:  304\n",
      "loss:  0.38827897237132575\n",
      "current time step:  305\n",
      "loss:  0.38827897237132575\n",
      "current time step:  306\n",
      "loss:  0.38827897237132575\n",
      "current time step:  307\n",
      "loss:  0.38827897237132575\n",
      "current time step:  308\n",
      "loss:  0.38827897237132575\n",
      "current time step:  309\n",
      "loss:  0.38827897237132575\n",
      "current time step:  310\n",
      "loss:  0.38827897237132575\n",
      "current time step:  311\n",
      "loss:  0.38827897237132575\n",
      "current time step:  312\n",
      "loss:  0.38827897237132575\n",
      "current time step:  313\n",
      "loss:  0.38827897237132575\n",
      "current time step:  314\n",
      "loss:  0.38827897237132575\n",
      "current time step:  315\n",
      "loss:  0.38827897237132575\n",
      "current time step:  316\n",
      "loss:  0.38827897237132575\n",
      "current time step:  317\n",
      "loss:  0.38827897237132575\n",
      "current time step:  318\n",
      "loss:  0.38827897237132575\n",
      "current time step:  319\n",
      "loss:  0.38827897237132575\n",
      "current time step:  320\n",
      "loss:  0.38827897237132575\n",
      "current time step:  321\n",
      "loss:  0.38827897237132575\n",
      "current time step:  322\n",
      "loss:  0.38827897237132575\n",
      "current time step:  323\n",
      "loss:  0.38827897237132575\n",
      "current time step:  324\n",
      "loss:  0.38827897237132575\n",
      "current time step:  325\n",
      "loss:  0.38827897237132575\n",
      "current time step:  326\n",
      "loss:  0.38827897237132575\n",
      "current time step:  327\n",
      "loss:  0.38827897237132575\n",
      "current time step:  328\n",
      "loss:  0.38827897237132575\n",
      "current time step:  329\n",
      "loss:  0.38827897237132575\n",
      "current time step:  330\n",
      "loss:  0.38827897237132575\n",
      "current time step:  331\n",
      "loss:  0.38827897237132575\n",
      "current time step:  332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.38827897237132575\n",
      "current time step:  333\n",
      "loss:  0.38827897237132575\n",
      "current time step:  334\n",
      "loss:  0.38827897237132575\n",
      "current time step:  335\n",
      "loss:  0.38827897237132575\n",
      "current time step:  336\n",
      "loss:  0.38827897237132575\n",
      "current time step:  337\n",
      "loss:  0.38827897237132575\n",
      "current time step:  338\n",
      "loss:  0.38827897237132575\n",
      "current time step:  339\n",
      "loss:  0.38827897237132575\n",
      "current time step:  340\n",
      "loss:  0.38827897237132575\n",
      "current time step:  341\n",
      "loss:  0.38827897237132575\n",
      "current time step:  342\n",
      "loss:  0.38827897237132575\n",
      "current time step:  343\n",
      "loss:  0.38827897237132575\n",
      "current time step:  344\n",
      "loss:  0.38827897237132575\n",
      "current time step:  345\n",
      "loss:  0.38827897237132575\n",
      "current time step:  346\n",
      "loss:  0.38827897237132575\n",
      "current time step:  347\n",
      "loss:  0.38827897237132575\n",
      "current time step:  348\n",
      "loss:  0.38827897237132575\n",
      "current time step:  349\n",
      "loss:  0.38827897237132575\n",
      "current time step:  350\n",
      "loss:  0.38827897237132575\n",
      "current time step:  351\n",
      "loss:  0.38827897237132575\n",
      "current time step:  352\n",
      "loss:  0.38827897237132575\n",
      "current time step:  353\n",
      "loss:  0.38827897237132575\n",
      "current time step:  354\n",
      "loss:  0.38827897237132575\n",
      "current time step:  355\n",
      "loss:  0.38827897237132575\n",
      "current time step:  356\n",
      "loss:  0.38827897237132575\n",
      "current time step:  357\n",
      "loss:  0.38827897237132575\n",
      "current time step:  358\n",
      "loss:  0.38827897237132575\n",
      "current time step:  359\n",
      "loss:  0.38827897237132575\n",
      "current time step:  360\n",
      "loss:  0.38827897237132575\n",
      "current time step:  361\n",
      "loss:  0.38827897237132575\n",
      "current time step:  362\n",
      "loss:  0.38827897237132575\n",
      "current time step:  363\n",
      "loss:  0.38827897237132575\n",
      "current time step:  364\n",
      "loss:  0.38827897237132575\n",
      "current time step:  365\n",
      "loss:  0.38827897237132575\n",
      "current time step:  366\n",
      "loss:  0.38827897237132575\n",
      "current time step:  367\n",
      "loss:  0.38827897237132575\n",
      "current time step:  368\n",
      "loss:  0.38827897237132575\n",
      "current time step:  369\n",
      "loss:  0.38827897237132575\n",
      "current time step:  370\n",
      "loss:  0.38827897237132575\n",
      "current time step:  371\n",
      "loss:  0.38827897237132575\n",
      "current time step:  372\n",
      "loss:  0.38827897237132575\n",
      "current time step:  373\n",
      "loss:  0.38827897237132575\n",
      "current time step:  374\n",
      "loss:  0.38827897237132575\n",
      "current time step:  375\n",
      "loss:  0.38827897237132575\n",
      "current time step:  376\n",
      "loss:  0.38827897237132575\n",
      "current time step:  377\n",
      "loss:  0.38827897237132575\n",
      "current time step:  378\n",
      "loss:  0.38827897237132575\n",
      "current time step:  379\n",
      "loss:  0.38827897237132575\n",
      "current time step:  380\n",
      "loss:  0.38827897237132575\n",
      "current time step:  381\n",
      "loss:  0.38827897237132575\n",
      "current time step:  382\n",
      "loss:  0.38827897237132575\n",
      "current time step:  383\n",
      "loss:  0.38827897237132575\n",
      "current time step:  384\n",
      "loss:  0.38827897237132575\n",
      "current time step:  385\n",
      "loss:  0.38827897237132575\n",
      "current time step:  386\n",
      "loss:  0.38827897237132575\n",
      "current time step:  387\n",
      "loss:  0.38827897237132575\n",
      "current time step:  388\n",
      "loss:  0.38827897237132575\n",
      "current time step:  389\n",
      "loss:  0.38827897237132575\n",
      "current time step:  390\n",
      "loss:  0.38827897237132575\n",
      "current time step:  391\n",
      "loss:  0.38827897237132575\n",
      "current time step:  392\n",
      "loss:  0.38827897237132575\n",
      "current time step:  393\n",
      "loss:  0.38827897237132575\n",
      "current time step:  394\n",
      "loss:  0.38827897237132575\n",
      "current time step:  395\n",
      "loss:  0.38827897237132575\n",
      "current time step:  396\n",
      "loss:  0.38827897237132575\n",
      "current time step:  397\n",
      "loss:  0.38827897237132575\n",
      "current time step:  398\n",
      "loss:  0.38827897237132575\n",
      "current time step:  399\n",
      "loss:  0.38827897237132575\n",
      "current time step:  400\n",
      "loss:  0.38827897237132575\n",
      "current time step:  401\n",
      "loss:  0.38827897237132575\n",
      "current time step:  402\n",
      "loss:  0.38827897237132575\n",
      "current time step:  403\n",
      "loss:  0.38827897237132575\n",
      "current time step:  404\n",
      "loss:  0.38827897237132575\n",
      "current time step:  405\n",
      "loss:  0.38827897237132575\n",
      "current time step:  406\n",
      "loss:  0.38827897237132575\n",
      "current time step:  407\n",
      "loss:  0.38827897237132575\n",
      "current time step:  408\n",
      "loss:  0.38827897237132575\n",
      "current time step:  409\n",
      "loss:  0.38827897237132575\n",
      "current time step:  410\n",
      "loss:  0.38827897237132575\n",
      "current time step:  411\n",
      "loss:  0.38827897237132575\n",
      "current time step:  412\n",
      "loss:  0.38827897237132575\n",
      "current time step:  413\n",
      "loss:  0.38827897237132575\n",
      "current time step:  414\n",
      "loss:  0.38827897237132575\n",
      "current time step:  415\n",
      "loss:  0.38827897237132575\n",
      "current time step:  416\n",
      "loss:  0.38827897237132575\n",
      "current time step:  417\n",
      "loss:  0.38827897237132575\n",
      "current time step:  418\n",
      "loss:  0.38827897237132575\n",
      "current time step:  419\n",
      "loss:  0.38827897237132575\n",
      "current time step:  420\n",
      "loss:  0.38827897237132575\n",
      "current time step:  421\n",
      "loss:  0.38827897237132575\n",
      "current time step:  422\n",
      "loss:  0.38827897237132575\n",
      "current time step:  423\n",
      "loss:  0.38827897237132575\n",
      "current time step:  424\n",
      "loss:  0.38827897237132575\n",
      "current time step:  425\n",
      "loss:  0.38827897237132575\n",
      "current time step:  426\n",
      "loss:  0.38827897237132575\n",
      "current time step:  427\n",
      "loss:  0.38827897237132575\n",
      "current time step:  428\n",
      "loss:  0.38827897237132575\n",
      "current time step:  429\n",
      "loss:  0.38827897237132575\n",
      "current time step:  430\n",
      "loss:  0.38827897237132575\n",
      "current time step:  431\n",
      "loss:  0.38827897237132575\n",
      "current time step:  432\n",
      "loss:  0.38827897237132575\n",
      "current time step:  433\n",
      "loss:  0.38827897237132575\n",
      "current time step:  434\n",
      "loss:  0.38827897237132575\n",
      "current time step:  435\n",
      "loss:  0.38827897237132575\n",
      "current time step:  436\n",
      "loss:  0.38827897237132575\n",
      "current time step:  437\n",
      "loss:  0.38827897237132575\n",
      "current time step:  438\n",
      "loss:  0.38827897237132575\n",
      "current time step:  439\n",
      "loss:  0.38827897237132575\n",
      "current time step:  440\n",
      "loss:  0.38827897237132575\n",
      "current time step:  441\n",
      "loss:  0.38827897237132575\n",
      "current time step:  442\n",
      "loss:  0.38827897237132575\n",
      "current time step:  443\n",
      "loss:  0.38827897237132575\n",
      "current time step:  444\n",
      "loss:  0.38827897237132575\n",
      "current time step:  445\n",
      "loss:  0.38827897237132575\n",
      "current time step:  446\n",
      "loss:  0.38827897237132575\n",
      "current time step:  447\n",
      "loss:  0.38827897237132575\n",
      "current time step:  448\n",
      "loss:  0.38827897237132575\n",
      "current time step:  449\n",
      "loss:  0.38827897237132575\n",
      "current time step:  450\n",
      "loss:  0.38827897237132575\n",
      "current time step:  451\n",
      "loss:  0.38827897237132575\n",
      "current time step:  452\n",
      "loss:  0.38827897237132575\n",
      "current time step:  453\n",
      "loss:  0.38827897237132575\n",
      "current time step:  454\n",
      "loss:  0.38827897237132575\n",
      "current time step:  455\n",
      "loss:  0.38827897237132575\n",
      "current time step:  456\n",
      "loss:  0.38827897237132575\n",
      "current time step:  457\n",
      "loss:  0.38827897237132575\n",
      "current time step:  458\n",
      "loss:  0.38827897237132575\n",
      "current time step:  459\n",
      "loss:  0.38827897237132575\n",
      "current time step:  460\n",
      "loss:  0.38827897237132575\n",
      "current time step:  461\n",
      "loss:  0.38827897237132575\n",
      "current time step:  462\n",
      "loss:  0.38827897237132575\n",
      "current time step:  463\n",
      "loss:  0.38827897237132575\n",
      "current time step:  464\n",
      "loss:  0.38827897237132575\n",
      "current time step:  465\n",
      "loss:  0.38827897237132575\n",
      "current time step:  466\n",
      "loss:  0.38827897237132575\n",
      "current time step:  467\n",
      "loss:  0.38827897237132575\n",
      "current time step:  468\n",
      "loss:  0.38827897237132575\n",
      "current time step:  469\n",
      "loss:  0.38827897237132575\n",
      "current time step:  470\n",
      "loss:  0.38827897237132575\n",
      "current time step:  471\n",
      "loss:  0.38827897237132575\n",
      "current time step:  472\n",
      "loss:  0.38827897237132575\n",
      "current time step:  473\n",
      "loss:  0.38827897237132575\n",
      "current time step:  474\n",
      "loss:  0.38827897237132575\n",
      "current time step:  475\n",
      "loss:  0.38827897237132575\n",
      "current time step:  476\n",
      "loss:  0.38827897237132575\n",
      "current time step:  477\n",
      "loss:  0.38827897237132575\n",
      "current time step:  478\n",
      "loss:  0.38827897237132575\n",
      "current time step:  479\n",
      "loss:  0.38827897237132575\n",
      "current time step:  480\n",
      "loss:  0.38827897237132575\n",
      "current time step:  481\n",
      "loss:  0.38827897237132575\n",
      "current time step:  482\n",
      "loss:  0.38827897237132575\n",
      "current time step:  483\n",
      "loss:  0.38827897237132575\n",
      "current time step:  484\n",
      "loss:  0.38827897237132575\n",
      "current time step:  485\n",
      "loss:  0.38827897237132575\n",
      "current time step:  486\n",
      "loss:  0.38827897237132575\n",
      "current time step:  487\n",
      "loss:  0.38827897237132575\n",
      "current time step:  488\n",
      "loss:  0.38827897237132575\n",
      "current time step:  489\n",
      "loss:  0.38827897237132575\n",
      "current time step:  490\n",
      "loss:  0.38827897237132575\n",
      "current time step:  491\n",
      "loss:  0.38827897237132575\n",
      "current time step:  492\n",
      "loss:  0.38827897237132575\n",
      "current time step:  493\n",
      "loss:  0.38827897237132575\n",
      "current time step:  494\n",
      "loss:  0.38827897237132575\n",
      "current time step:  495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.38827897237132575\n",
      "current time step:  496\n",
      "loss:  0.38827897237132575\n",
      "current time step:  497\n",
      "loss:  0.38827897237132575\n",
      "current time step:  498\n",
      "loss:  0.38827897237132575\n",
      "current time step:  499\n",
      "loss:  0.38827897237132575\n",
      "current time step:  500\n",
      "loss:  0.38827897237132575\n",
      "current time step:  501\n",
      "loss:  0.38827897237132575\n",
      "current time step:  502\n",
      "loss:  0.38827897237132575\n",
      "current time step:  503\n",
      "loss:  0.38827897237132575\n",
      "current time step:  504\n",
      "loss:  0.38827897237132575\n",
      "current time step:  505\n",
      "loss:  0.38827897237132575\n",
      "current time step:  506\n",
      "loss:  0.38827897237132575\n",
      "current time step:  507\n",
      "loss:  0.38827897237132575\n",
      "current time step:  508\n",
      "loss:  0.38827897237132575\n",
      "current time step:  509\n",
      "loss:  0.38827897237132575\n",
      "current time step:  510\n",
      "loss:  0.38827897237132575\n",
      "current time step:  511\n",
      "loss:  0.38827897237132575\n",
      "current time step:  512\n",
      "loss:  0.38827897237132575\n",
      "current time step:  513\n",
      "loss:  0.38827897237132575\n",
      "current time step:  514\n",
      "loss:  0.38827897237132575\n",
      "current time step:  515\n",
      "loss:  0.38827897237132575\n",
      "current time step:  516\n",
      "loss:  0.38827897237132575\n",
      "current time step:  517\n",
      "loss:  0.38827897237132575\n",
      "current time step:  518\n",
      "loss:  0.38827897237132575\n",
      "current time step:  519\n",
      "loss:  0.38827897237132575\n",
      "current time step:  520\n",
      "loss:  0.38827897237132575\n",
      "current time step:  521\n",
      "loss:  0.38827897237132575\n",
      "current time step:  522\n",
      "loss:  0.38827897237132575\n",
      "current time step:  523\n",
      "loss:  0.38827897237132575\n",
      "current time step:  524\n",
      "loss:  0.38827897237132575\n",
      "current time step:  525\n",
      "loss:  0.38827897237132575\n",
      "current time step:  526\n",
      "loss:  0.38827897237132575\n",
      "current time step:  527\n",
      "loss:  0.38827897237132575\n",
      "current time step:  528\n",
      "loss:  0.38827897237132575\n",
      "current time step:  529\n",
      "loss:  0.38827897237132575\n",
      "current time step:  530\n",
      "loss:  0.38827897237132575\n",
      "current time step:  531\n",
      "loss:  0.38827897237132575\n",
      "current time step:  532\n",
      "loss:  0.38827897237132575\n",
      "current time step:  533\n",
      "loss:  0.38827897237132575\n",
      "current time step:  534\n",
      "loss:  0.38827897237132575\n",
      "current time step:  535\n",
      "loss:  0.38827897237132575\n",
      "current time step:  536\n",
      "loss:  0.38827897237132575\n",
      "current time step:  537\n",
      "loss:  0.38827897237132575\n",
      "current time step:  538\n",
      "loss:  0.38827897237132575\n",
      "current time step:  539\n",
      "loss:  0.38827897237132575\n",
      "current time step:  540\n",
      "loss:  0.38827897237132575\n",
      "current time step:  541\n",
      "loss:  0.38827897237132575\n",
      "current time step:  542\n",
      "loss:  0.38827897237132575\n",
      "current time step:  543\n",
      "loss:  0.38827897237132575\n",
      "current time step:  544\n",
      "loss:  0.38827897237132575\n",
      "current time step:  545\n",
      "loss:  0.38827897237132575\n",
      "current time step:  546\n",
      "loss:  0.38827897237132575\n",
      "current time step:  547\n",
      "loss:  0.38827897237132575\n",
      "current time step:  548\n",
      "loss:  0.38827897237132575\n",
      "current time step:  549\n",
      "loss:  0.38827897237132575\n",
      "current time step:  550\n",
      "loss:  0.38827897237132575\n",
      "current time step:  551\n",
      "loss:  0.38827897237132575\n",
      "current time step:  552\n",
      "loss:  0.38827897237132575\n",
      "current time step:  553\n",
      "loss:  0.38827897237132575\n",
      "current time step:  554\n",
      "loss:  0.38827897237132575\n",
      "current time step:  555\n",
      "loss:  0.38827897237132575\n",
      "current time step:  556\n",
      "loss:  0.38827897237132575\n",
      "current time step:  557\n",
      "loss:  0.38827897237132575\n",
      "current time step:  558\n",
      "loss:  0.38827897237132575\n",
      "current time step:  559\n",
      "loss:  0.38827897237132575\n",
      "current time step:  560\n",
      "loss:  0.38827897237132575\n",
      "current time step:  561\n",
      "loss:  0.38827897237132575\n",
      "current time step:  562\n",
      "loss:  0.38827897237132575\n",
      "current time step:  563\n",
      "loss:  0.38827897237132575\n",
      "current time step:  564\n",
      "loss:  0.38827897237132575\n",
      "current time step:  565\n",
      "loss:  0.38827897237132575\n",
      "current time step:  566\n",
      "loss:  0.38827897237132575\n",
      "current time step:  567\n",
      "loss:  0.38827897237132575\n",
      "current time step:  568\n",
      "loss:  0.38827897237132575\n",
      "current time step:  569\n",
      "loss:  0.38827897237132575\n",
      "current time step:  570\n",
      "loss:  0.38827897237132575\n",
      "current time step:  571\n",
      "loss:  0.38827897237132575\n",
      "current time step:  572\n",
      "loss:  0.38827897237132575\n",
      "current time step:  573\n",
      "loss:  0.38827897237132575\n",
      "current time step:  574\n",
      "loss:  0.38827897237132575\n",
      "current time step:  575\n",
      "loss:  0.38827897237132575\n",
      "current time step:  576\n",
      "loss:  0.38827897237132575\n",
      "current time step:  577\n",
      "loss:  0.38827897237132575\n",
      "current time step:  578\n",
      "loss:  0.38827897237132575\n",
      "current time step:  579\n",
      "loss:  0.38827897237132575\n",
      "current time step:  580\n",
      "loss:  0.38827897237132575\n",
      "current time step:  581\n",
      "loss:  0.38827897237132575\n",
      "current time step:  582\n",
      "loss:  0.38827897237132575\n",
      "current time step:  583\n",
      "loss:  0.38827897237132575\n",
      "current time step:  584\n",
      "loss:  0.38827897237132575\n",
      "current time step:  585\n",
      "loss:  0.38827897237132575\n",
      "current time step:  586\n",
      "loss:  0.38827897237132575\n",
      "current time step:  587\n",
      "loss:  0.38827897237132575\n",
      "current time step:  588\n",
      "loss:  0.38827897237132575\n",
      "current time step:  589\n",
      "loss:  0.38827897237132575\n",
      "current time step:  590\n",
      "loss:  0.38827897237132575\n",
      "current time step:  591\n",
      "loss:  0.38827897237132575\n",
      "current time step:  592\n",
      "loss:  0.38827897237132575\n",
      "current time step:  593\n",
      "loss:  0.38827897237132575\n",
      "current time step:  594\n",
      "loss:  0.38827897237132575\n",
      "current time step:  595\n",
      "loss:  0.38827897237132575\n",
      "current time step:  596\n",
      "loss:  0.38827897237132575\n",
      "current time step:  597\n",
      "loss:  0.38827897237132575\n",
      "current time step:  598\n",
      "loss:  0.38827897237132575\n",
      "current time step:  599\n",
      "loss:  0.38827897237132575\n",
      "current time step:  600\n",
      "loss:  0.38827897237132575\n",
      "current time step:  601\n",
      "loss:  0.38827897237132575\n",
      "current time step:  602\n",
      "loss:  0.38827897237132575\n",
      "current time step:  603\n",
      "loss:  0.38827897237132575\n",
      "current time step:  604\n",
      "loss:  0.38827897237132575\n",
      "current time step:  605\n",
      "loss:  0.38827897237132575\n",
      "current time step:  606\n",
      "loss:  0.38827897237132575\n",
      "current time step:  607\n",
      "loss:  0.38827897237132575\n",
      "current time step:  608\n",
      "loss:  0.38827897237132575\n",
      "current time step:  609\n",
      "loss:  0.38827897237132575\n",
      "current time step:  610\n",
      "loss:  0.38827897237132575\n",
      "current time step:  611\n",
      "loss:  0.38827897237132575\n",
      "current time step:  612\n",
      "loss:  0.38827897237132575\n",
      "current time step:  613\n",
      "loss:  0.38827897237132575\n",
      "current time step:  614\n",
      "loss:  0.38827897237132575\n",
      "current time step:  615\n",
      "loss:  0.38827897237132575\n",
      "current time step:  616\n",
      "loss:  0.38827897237132575\n",
      "current time step:  617\n",
      "loss:  0.38827897237132575\n",
      "current time step:  618\n",
      "loss:  0.38827897237132575\n",
      "current time step:  619\n",
      "loss:  0.38827897237132575\n",
      "current time step:  620\n",
      "loss:  0.38827897237132575\n",
      "current time step:  621\n",
      "loss:  0.38827897237132575\n",
      "current time step:  622\n",
      "loss:  0.38827897237132575\n",
      "current time step:  623\n",
      "loss:  0.38827897237132575\n",
      "current time step:  624\n",
      "loss:  0.38827897237132575\n",
      "current time step:  625\n",
      "loss:  0.38827897237132575\n",
      "current time step:  626\n",
      "loss:  0.38827897237132575\n",
      "current time step:  627\n",
      "loss:  0.38827897237132575\n",
      "current time step:  628\n",
      "loss:  0.38827897237132575\n",
      "current time step:  629\n",
      "loss:  0.38827897237132575\n",
      "current time step:  630\n",
      "loss:  0.38827897237132575\n",
      "current time step:  631\n",
      "loss:  0.38827897237132575\n",
      "current time step:  632\n",
      "loss:  0.38827897237132575\n",
      "current time step:  633\n",
      "loss:  0.38827897237132575\n",
      "current time step:  634\n",
      "loss:  0.38827897237132575\n",
      "current time step:  635\n",
      "loss:  0.38827897237132575\n",
      "current time step:  636\n",
      "loss:  0.38827897237132575\n",
      "current time step:  637\n",
      "loss:  0.38827897237132575\n",
      "current time step:  638\n",
      "loss:  0.38827897237132575\n",
      "current time step:  639\n",
      "loss:  0.38827897237132575\n",
      "current time step:  640\n",
      "loss:  0.38827897237132575\n",
      "current time step:  641\n",
      "loss:  0.38827897237132575\n",
      "current time step:  642\n",
      "loss:  0.38827897237132575\n",
      "current time step:  643\n",
      "loss:  0.38827897237132575\n",
      "current time step:  644\n",
      "loss:  0.38827897237132575\n",
      "current time step:  645\n",
      "loss:  0.38827897237132575\n",
      "current time step:  646\n",
      "loss:  0.38827897237132575\n",
      "current time step:  647\n",
      "loss:  0.38827897237132575\n",
      "current time step:  648\n",
      "loss:  0.38827897237132575\n",
      "current time step:  649\n",
      "loss:  0.38827897237132575\n",
      "current time step:  650\n",
      "loss:  0.38827897237132575\n",
      "current time step:  651\n",
      "loss:  0.38827897237132575\n",
      "current time step:  652\n",
      "loss:  0.38827897237132575\n",
      "current time step:  653\n",
      "loss:  0.38827897237132575\n",
      "current time step:  654\n",
      "loss:  0.38827897237132575\n",
      "current time step:  655\n",
      "loss:  0.38827897237132575\n",
      "current time step:  656\n",
      "loss:  0.38827897237132575\n",
      "current time step:  657\n",
      "loss:  0.38827897237132575\n",
      "current time step:  658\n",
      "loss:  0.38827897237132575\n",
      "current time step:  659\n",
      "loss:  0.38827897237132575\n",
      "current time step:  660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.38827897237132575\n",
      "current time step:  661\n",
      "loss:  0.38827897237132575\n",
      "current time step:  662\n",
      "loss:  0.38827897237132575\n",
      "current time step:  663\n",
      "loss:  0.38827897237132575\n",
      "current time step:  664\n",
      "loss:  0.38827897237132575\n",
      "current time step:  665\n",
      "loss:  0.38827897237132575\n",
      "current time step:  666\n",
      "loss:  0.38827897237132575\n",
      "current time step:  667\n",
      "loss:  0.38827897237132575\n",
      "current time step:  668\n",
      "loss:  0.38827897237132575\n",
      "current time step:  669\n",
      "loss:  0.38827897237132575\n",
      "current time step:  670\n",
      "loss:  0.38827897237132575\n",
      "current time step:  671\n",
      "loss:  0.38827897237132575\n",
      "current time step:  672\n",
      "loss:  0.38827897237132575\n",
      "current time step:  673\n",
      "loss:  0.38827897237132575\n",
      "current time step:  674\n",
      "loss:  0.38827897237132575\n",
      "current time step:  675\n",
      "loss:  0.38827897237132575\n",
      "current time step:  676\n",
      "loss:  0.38827897237132575\n",
      "current time step:  677\n",
      "loss:  0.38827897237132575\n",
      "current time step:  678\n",
      "loss:  0.38827897237132575\n",
      "current time step:  679\n",
      "loss:  0.38827897237132575\n",
      "current time step:  680\n",
      "loss:  0.38827897237132575\n",
      "current time step:  681\n",
      "loss:  0.38827897237132575\n",
      "current time step:  682\n",
      "loss:  0.38827897237132575\n",
      "current time step:  683\n",
      "loss:  0.38827897237132575\n",
      "current time step:  684\n",
      "loss:  0.38827897237132575\n",
      "current time step:  685\n",
      "loss:  0.38827897237132575\n",
      "current time step:  686\n",
      "loss:  0.38827897237132575\n",
      "current time step:  687\n",
      "loss:  0.38827897237132575\n",
      "current time step:  688\n",
      "loss:  0.38827897237132575\n",
      "current time step:  689\n",
      "loss:  0.38827897237132575\n",
      "current time step:  690\n",
      "loss:  0.38827897237132575\n",
      "current time step:  691\n",
      "loss:  0.38827897237132575\n",
      "current time step:  692\n",
      "loss:  0.38827897237132575\n",
      "current time step:  693\n",
      "loss:  0.38827897237132575\n",
      "current time step:  694\n",
      "loss:  0.38827897237132575\n",
      "current time step:  695\n",
      "loss:  0.38827897237132575\n",
      "current time step:  696\n",
      "loss:  0.38827897237132575\n",
      "current time step:  697\n",
      "loss:  0.38827897237132575\n",
      "current time step:  698\n",
      "loss:  0.38827897237132575\n",
      "current time step:  699\n",
      "loss:  0.38827897237132575\n",
      "current time step:  700\n",
      "loss:  0.38827897237132575\n",
      "current time step:  701\n",
      "loss:  0.38827897237132575\n",
      "current time step:  702\n",
      "loss:  0.38827897237132575\n",
      "current time step:  703\n",
      "loss:  0.38827897237132575\n",
      "current time step:  704\n",
      "loss:  0.38827897237132575\n",
      "current time step:  705\n",
      "loss:  0.38827897237132575\n",
      "current time step:  706\n",
      "loss:  0.38827897237132575\n",
      "current time step:  707\n",
      "loss:  0.38827897237132575\n",
      "current time step:  708\n",
      "loss:  0.38827897237132575\n",
      "current time step:  709\n",
      "loss:  0.38827897237132575\n",
      "current time step:  710\n",
      "loss:  0.38827897237132575\n",
      "current time step:  711\n",
      "loss:  0.38827897237132575\n",
      "current time step:  712\n",
      "loss:  0.38827897237132575\n",
      "current time step:  713\n",
      "loss:  0.38827897237132575\n",
      "current time step:  714\n",
      "loss:  0.38827897237132575\n",
      "current time step:  715\n",
      "loss:  0.38827897237132575\n",
      "current time step:  716\n",
      "loss:  0.38827897237132575\n",
      "current time step:  717\n",
      "loss:  0.38827897237132575\n",
      "current time step:  718\n",
      "loss:  0.38827897237132575\n",
      "current time step:  719\n",
      "loss:  0.38827897237132575\n",
      "current time step:  720\n",
      "loss:  0.38827897237132575\n",
      "current time step:  721\n",
      "loss:  0.38827897237132575\n",
      "current time step:  722\n",
      "loss:  0.38827897237132575\n",
      "current time step:  723\n",
      "loss:  0.38827897237132575\n",
      "current time step:  724\n",
      "loss:  0.38827897237132575\n",
      "current time step:  725\n",
      "loss:  0.38827897237132575\n",
      "current time step:  726\n",
      "loss:  0.38827897237132575\n",
      "current time step:  727\n",
      "loss:  0.38827897237132575\n",
      "current time step:  728\n",
      "loss:  0.38827897237132575\n",
      "current time step:  729\n",
      "loss:  0.38827897237132575\n",
      "current time step:  730\n",
      "loss:  0.38827897237132575\n",
      "current time step:  731\n",
      "loss:  0.38827897237132575\n",
      "current time step:  732\n",
      "loss:  0.38827897237132575\n",
      "current time step:  733\n",
      "loss:  0.38827897237132575\n",
      "current time step:  734\n",
      "loss:  0.38827897237132575\n",
      "current time step:  735\n",
      "loss:  0.38827897237132575\n",
      "current time step:  736\n",
      "loss:  0.38827897237132575\n",
      "current time step:  737\n",
      "loss:  0.38827897237132575\n",
      "current time step:  738\n",
      "loss:  0.38827897237132575\n",
      "current time step:  739\n",
      "loss:  0.38827897237132575\n",
      "current time step:  740\n",
      "loss:  0.38827897237132575\n",
      "current time step:  741\n",
      "loss:  0.38827897237132575\n",
      "current time step:  742\n",
      "loss:  0.38827897237132575\n",
      "current time step:  743\n",
      "loss:  0.38827897237132575\n",
      "current time step:  744\n",
      "loss:  0.38827897237132575\n",
      "current time step:  745\n",
      "loss:  0.38827897237132575\n",
      "current time step:  746\n",
      "loss:  0.38827897237132575\n",
      "current time step:  747\n",
      "loss:  0.38827897237132575\n",
      "current time step:  748\n",
      "loss:  0.38827897237132575\n",
      "current time step:  749\n",
      "loss:  0.38827897237132575\n",
      "current time step:  750\n",
      "loss:  0.38827897237132575\n",
      "current time step:  751\n",
      "loss:  0.38827897237132575\n",
      "current time step:  752\n",
      "loss:  0.38827897237132575\n",
      "current time step:  753\n",
      "loss:  0.38827897237132575\n",
      "current time step:  754\n",
      "loss:  0.38827897237132575\n",
      "current time step:  755\n",
      "loss:  0.38827897237132575\n",
      "current time step:  756\n",
      "loss:  0.38827897237132575\n",
      "current time step:  757\n",
      "loss:  0.38827897237132575\n",
      "current time step:  758\n",
      "loss:  0.38827897237132575\n",
      "current time step:  759\n",
      "loss:  0.38827897237132575\n",
      "current time step:  760\n",
      "loss:  0.38827897237132575\n",
      "current time step:  761\n",
      "loss:  0.38827897237132575\n",
      "current time step:  762\n",
      "loss:  0.38827897237132575\n",
      "current time step:  763\n",
      "loss:  0.38827897237132575\n",
      "current time step:  764\n",
      "loss:  0.38827897237132575\n",
      "current time step:  765\n",
      "loss:  0.38827897237132575\n",
      "current time step:  766\n",
      "loss:  0.38827897237132575\n",
      "current time step:  767\n",
      "loss:  0.38827897237132575\n",
      "current time step:  768\n",
      "loss:  0.38827897237132575\n",
      "current time step:  769\n",
      "loss:  0.38827897237132575\n",
      "current time step:  770\n",
      "loss:  0.38827897237132575\n",
      "current time step:  771\n",
      "loss:  0.38827897237132575\n",
      "current time step:  772\n",
      "loss:  0.38827897237132575\n",
      "current time step:  773\n",
      "loss:  0.38827897237132575\n",
      "current time step:  774\n",
      "loss:  0.38827897237132575\n",
      "current time step:  775\n",
      "loss:  0.38827897237132575\n",
      "current time step:  776\n",
      "loss:  0.38827897237132575\n",
      "current time step:  777\n",
      "loss:  0.38827897237132575\n",
      "current time step:  778\n",
      "loss:  0.38827897237132575\n",
      "current time step:  779\n",
      "loss:  0.38827897237132575\n",
      "current time step:  780\n",
      "loss:  0.38827897237132575\n",
      "current time step:  781\n",
      "loss:  0.38827897237132575\n",
      "current time step:  782\n",
      "loss:  0.38827897237132575\n",
      "current time step:  783\n",
      "loss:  0.38827897237132575\n",
      "current time step:  784\n",
      "loss:  0.38827897237132575\n",
      "current time step:  785\n",
      "loss:  0.38827897237132575\n",
      "current time step:  786\n",
      "loss:  0.38827897237132575\n",
      "current time step:  787\n",
      "loss:  0.38827897237132575\n",
      "current time step:  788\n",
      "loss:  0.38827897237132575\n",
      "current time step:  789\n",
      "loss:  0.38827897237132575\n",
      "current time step:  790\n",
      "loss:  0.38827897237132575\n",
      "current time step:  791\n",
      "loss:  0.38827897237132575\n",
      "current time step:  792\n",
      "loss:  0.38827897237132575\n",
      "current time step:  793\n",
      "loss:  0.38827897237132575\n",
      "current time step:  794\n",
      "loss:  0.38827897237132575\n",
      "current time step:  795\n",
      "loss:  0.38827897237132575\n",
      "current time step:  796\n",
      "loss:  0.38827897237132575\n",
      "current time step:  797\n",
      "loss:  0.38827897237132575\n",
      "current time step:  798\n",
      "loss:  0.38827897237132575\n",
      "current time step:  799\n",
      "loss:  0.38827897237132575\n",
      "current time step:  800\n",
      "loss:  0.38827897237132575\n",
      "current time step:  801\n",
      "loss:  0.38827897237132575\n",
      "current time step:  802\n",
      "loss:  0.38827897237132575\n",
      "current time step:  803\n",
      "loss:  0.38827897237132575\n",
      "current time step:  804\n",
      "loss:  0.38827897237132575\n",
      "current time step:  805\n",
      "loss:  0.38827897237132575\n",
      "current time step:  806\n",
      "loss:  0.38827897237132575\n",
      "current time step:  807\n",
      "loss:  0.38827897237132575\n",
      "current time step:  808\n",
      "loss:  0.38827897237132575\n",
      "current time step:  809\n",
      "loss:  0.38827897237132575\n",
      "current time step:  810\n",
      "loss:  0.38827897237132575\n",
      "current time step:  811\n",
      "loss:  0.38827897237132575\n",
      "current time step:  812\n",
      "loss:  0.38827897237132575\n",
      "current time step:  813\n",
      "loss:  0.38827897237132575\n",
      "current time step:  814\n",
      "loss:  0.38827897237132575\n",
      "current time step:  815\n",
      "loss:  0.38827897237132575\n",
      "current time step:  816\n",
      "loss:  0.38827897237132575\n",
      "current time step:  817\n",
      "loss:  0.38827897237132575\n",
      "current time step:  818\n",
      "loss:  0.38827897237132575\n",
      "current time step:  819\n",
      "loss:  0.38827897237132575\n",
      "current time step:  820\n",
      "loss:  0.38827897237132575\n",
      "current time step:  821\n",
      "loss:  0.38827897237132575\n",
      "current time step:  822\n",
      "loss:  0.38827897237132575\n",
      "current time step:  823\n",
      "loss:  0.38827897237132575\n",
      "current time step:  824\n",
      "loss:  0.38827897237132575\n",
      "current time step:  825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.38827897237132575\n",
      "current time step:  826\n",
      "loss:  0.38827897237132575\n",
      "current time step:  827\n",
      "loss:  0.38827897237132575\n",
      "current time step:  828\n",
      "loss:  0.38827897237132575\n",
      "current time step:  829\n",
      "loss:  0.38827897237132575\n",
      "current time step:  830\n",
      "loss:  0.38827897237132575\n",
      "current time step:  831\n",
      "loss:  0.38827897237132575\n",
      "current time step:  832\n",
      "loss:  0.38827897237132575\n",
      "current time step:  833\n",
      "loss:  0.38827897237132575\n",
      "current time step:  834\n",
      "loss:  0.38827897237132575\n",
      "current time step:  835\n",
      "loss:  0.38827897237132575\n",
      "current time step:  836\n",
      "loss:  0.38827897237132575\n",
      "current time step:  837\n",
      "loss:  0.38827897237132575\n",
      "current time step:  838\n",
      "loss:  0.38827897237132575\n",
      "current time step:  839\n",
      "loss:  0.38827897237132575\n",
      "current time step:  840\n",
      "loss:  0.38827897237132575\n",
      "current time step:  841\n",
      "loss:  0.38827897237132575\n",
      "current time step:  842\n",
      "loss:  0.38827897237132575\n",
      "current time step:  843\n",
      "loss:  0.38827897237132575\n",
      "current time step:  844\n",
      "loss:  0.38827897237132575\n",
      "current time step:  845\n",
      "loss:  0.38827897237132575\n",
      "current time step:  846\n",
      "loss:  0.38827897237132575\n",
      "current time step:  847\n",
      "loss:  0.38827897237132575\n",
      "current time step:  848\n",
      "loss:  0.38827897237132575\n",
      "current time step:  849\n",
      "loss:  0.38827897237132575\n",
      "current time step:  850\n",
      "loss:  0.38827897237132575\n",
      "current time step:  851\n",
      "loss:  0.38827897237132575\n",
      "current time step:  852\n",
      "loss:  0.38827897237132575\n",
      "current time step:  853\n",
      "loss:  0.38827897237132575\n",
      "current time step:  854\n",
      "loss:  0.38827897237132575\n",
      "current time step:  855\n",
      "loss:  0.38827897237132575\n",
      "current time step:  856\n",
      "loss:  0.38827897237132575\n",
      "current time step:  857\n",
      "loss:  0.38827897237132575\n",
      "current time step:  858\n",
      "loss:  0.38827897237132575\n",
      "current time step:  859\n",
      "loss:  0.38827897237132575\n",
      "current time step:  860\n",
      "loss:  0.38827897237132575\n",
      "current time step:  861\n",
      "loss:  0.38827897237132575\n",
      "current time step:  862\n",
      "loss:  0.38827897237132575\n",
      "current time step:  863\n",
      "loss:  0.38827897237132575\n",
      "current time step:  864\n",
      "loss:  0.38827897237132575\n",
      "current time step:  865\n",
      "loss:  0.38827897237132575\n",
      "current time step:  866\n",
      "loss:  0.38827897237132575\n",
      "current time step:  867\n",
      "loss:  0.38827897237132575\n",
      "current time step:  868\n",
      "loss:  0.38827897237132575\n",
      "current time step:  869\n",
      "loss:  0.38827897237132575\n",
      "current time step:  870\n",
      "loss:  0.38827897237132575\n",
      "current time step:  871\n",
      "loss:  0.38827897237132575\n",
      "current time step:  872\n",
      "loss:  0.38827897237132575\n",
      "current time step:  873\n",
      "loss:  0.38827897237132575\n",
      "current time step:  874\n",
      "loss:  0.38827897237132575\n",
      "current time step:  875\n",
      "loss:  0.38827897237132575\n",
      "current time step:  876\n",
      "loss:  0.38827897237132575\n",
      "current time step:  877\n",
      "loss:  0.38827897237132575\n",
      "current time step:  878\n",
      "loss:  0.38827897237132575\n",
      "current time step:  879\n",
      "loss:  0.38827897237132575\n",
      "current time step:  880\n",
      "loss:  0.38827897237132575\n",
      "current time step:  881\n",
      "loss:  0.38827897237132575\n",
      "current time step:  882\n",
      "loss:  0.38827897237132575\n",
      "current time step:  883\n",
      "loss:  0.38827897237132575\n",
      "current time step:  884\n",
      "loss:  0.38827897237132575\n",
      "current time step:  885\n",
      "loss:  0.38827897237132575\n",
      "current time step:  886\n",
      "loss:  0.38827897237132575\n",
      "current time step:  887\n",
      "loss:  0.38827897237132575\n",
      "current time step:  888\n",
      "loss:  0.38827897237132575\n",
      "current time step:  889\n",
      "loss:  0.38827897237132575\n",
      "current time step:  890\n",
      "loss:  0.38827897237132575\n",
      "current time step:  891\n",
      "loss:  0.38827897237132575\n",
      "current time step:  892\n",
      "loss:  0.38827897237132575\n",
      "current time step:  893\n",
      "loss:  0.38827897237132575\n",
      "current time step:  894\n",
      "loss:  0.38827897237132575\n",
      "current time step:  895\n",
      "loss:  0.38827897237132575\n",
      "current time step:  896\n",
      "loss:  0.38827897237132575\n",
      "current time step:  897\n",
      "loss:  0.38827897237132575\n",
      "current time step:  898\n",
      "loss:  0.38827897237132575\n",
      "current time step:  899\n",
      "loss:  0.38827897237132575\n",
      "current time step:  900\n",
      "loss:  0.38827897237132575\n",
      "current time step:  901\n",
      "loss:  0.38827897237132575\n",
      "current time step:  902\n",
      "loss:  0.38827897237132575\n",
      "current time step:  903\n",
      "loss:  0.38827897237132575\n",
      "current time step:  904\n",
      "loss:  0.38827897237132575\n",
      "current time step:  905\n",
      "loss:  0.38827897237132575\n",
      "current time step:  906\n",
      "loss:  0.38827897237132575\n",
      "current time step:  907\n",
      "loss:  0.38827897237132575\n",
      "current time step:  908\n",
      "loss:  0.38827897237132575\n",
      "current time step:  909\n",
      "loss:  0.38827897237132575\n",
      "current time step:  910\n",
      "loss:  0.38827897237132575\n",
      "current time step:  911\n",
      "loss:  0.38827897237132575\n",
      "current time step:  912\n",
      "loss:  0.38827897237132575\n",
      "current time step:  913\n",
      "loss:  0.38827897237132575\n",
      "current time step:  914\n",
      "loss:  0.38827897237132575\n",
      "current time step:  915\n",
      "loss:  0.38827897237132575\n",
      "current time step:  916\n",
      "loss:  0.38827897237132575\n",
      "current time step:  917\n",
      "loss:  0.38827897237132575\n",
      "current time step:  918\n",
      "loss:  0.38827897237132575\n",
      "current time step:  919\n",
      "loss:  0.38827897237132575\n",
      "current time step:  920\n",
      "loss:  0.38827897237132575\n",
      "current time step:  921\n",
      "loss:  0.38827897237132575\n",
      "current time step:  922\n",
      "loss:  0.38827897237132575\n",
      "current time step:  923\n",
      "loss:  0.38827897237132575\n",
      "current time step:  924\n",
      "loss:  0.38827897237132575\n",
      "current time step:  925\n",
      "loss:  0.38827897237132575\n",
      "current time step:  926\n",
      "loss:  0.38827897237132575\n",
      "current time step:  927\n",
      "loss:  0.38827897237132575\n",
      "current time step:  928\n",
      "loss:  0.38827897237132575\n",
      "current time step:  929\n",
      "loss:  0.38827897237132575\n",
      "current time step:  930\n",
      "loss:  0.38827897237132575\n",
      "current time step:  931\n",
      "loss:  0.38827897237132575\n",
      "current time step:  932\n",
      "loss:  0.38827897237132575\n",
      "current time step:  933\n",
      "loss:  0.38827897237132575\n",
      "current time step:  934\n",
      "loss:  0.38827897237132575\n",
      "current time step:  935\n",
      "loss:  0.38827897237132575\n",
      "current time step:  936\n",
      "loss:  0.38827897237132575\n",
      "current time step:  937\n",
      "loss:  0.38827897237132575\n",
      "current time step:  938\n",
      "loss:  0.38827897237132575\n",
      "current time step:  939\n",
      "loss:  0.38827897237132575\n",
      "current time step:  940\n",
      "loss:  0.38827897237132575\n",
      "current time step:  941\n",
      "loss:  0.38827897237132575\n",
      "current time step:  942\n",
      "loss:  0.38827897237132575\n",
      "current time step:  943\n",
      "loss:  0.38827897237132575\n",
      "current time step:  944\n",
      "loss:  0.38827897237132575\n",
      "current time step:  945\n",
      "loss:  0.38827897237132575\n",
      "current time step:  946\n",
      "loss:  0.38827897237132575\n",
      "current time step:  947\n",
      "loss:  0.38827897237132575\n",
      "current time step:  948\n",
      "loss:  0.38827897237132575\n",
      "current time step:  949\n",
      "loss:  0.38827897237132575\n",
      "current time step:  950\n",
      "loss:  0.38827897237132575\n",
      "current time step:  951\n",
      "loss:  0.38827897237132575\n",
      "current time step:  952\n",
      "loss:  0.38827897237132575\n",
      "current time step:  953\n",
      "loss:  0.38827897237132575\n",
      "current time step:  954\n",
      "loss:  0.38827897237132575\n",
      "current time step:  955\n",
      "loss:  0.38827897237132575\n",
      "current time step:  956\n",
      "loss:  0.38827897237132575\n",
      "current time step:  957\n",
      "loss:  0.38827897237132575\n",
      "current time step:  958\n",
      "loss:  0.38827897237132575\n",
      "current time step:  959\n",
      "loss:  0.38827897237132575\n",
      "current time step:  960\n",
      "loss:  0.38827897237132575\n",
      "current time step:  961\n",
      "loss:  0.38827897237132575\n",
      "current time step:  962\n",
      "loss:  0.38827897237132575\n",
      "current time step:  963\n",
      "loss:  0.38827897237132575\n",
      "current time step:  964\n",
      "loss:  0.38827897237132575\n",
      "current time step:  965\n",
      "loss:  0.38827897237132575\n",
      "current time step:  966\n",
      "loss:  0.38827897237132575\n",
      "current time step:  967\n",
      "loss:  0.38827897237132575\n",
      "current time step:  968\n",
      "loss:  0.38827897237132575\n",
      "current time step:  969\n",
      "loss:  0.38827897237132575\n",
      "current time step:  970\n",
      "loss:  0.38827897237132575\n",
      "current time step:  971\n",
      "loss:  0.38827897237132575\n",
      "current time step:  972\n",
      "loss:  0.38827897237132575\n",
      "current time step:  973\n",
      "loss:  0.38827897237132575\n",
      "current time step:  974\n",
      "loss:  0.38827897237132575\n",
      "current time step:  975\n",
      "loss:  0.38827897237132575\n",
      "current time step:  976\n",
      "loss:  0.38827897237132575\n",
      "current time step:  977\n",
      "loss:  0.38827897237132575\n",
      "current time step:  978\n",
      "loss:  0.38827897237132575\n",
      "current time step:  979\n",
      "loss:  0.38827897237132575\n",
      "current time step:  980\n",
      "loss:  0.38827897237132575\n",
      "current time step:  981\n",
      "loss:  0.38827897237132575\n",
      "current time step:  982\n",
      "loss:  0.38827897237132575\n",
      "current time step:  983\n",
      "loss:  0.38827897237132575\n",
      "current time step:  984\n",
      "loss:  0.38827897237132575\n",
      "current time step:  985\n",
      "loss:  0.38827897237132575\n",
      "current time step:  986\n",
      "loss:  0.38827897237132575\n",
      "current time step:  987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.38827897237132575\n",
      "current time step:  988\n",
      "loss:  0.38827897237132575\n",
      "current time step:  989\n",
      "loss:  0.38827897237132575\n",
      "current time step:  990\n",
      "loss:  0.38827897237132575\n",
      "current time step:  991\n",
      "loss:  0.38827897237132575\n",
      "current time step:  992\n",
      "loss:  0.38827897237132575\n",
      "current time step:  993\n",
      "loss:  0.38827897237132575\n",
      "current time step:  994\n",
      "loss:  0.38827897237132575\n",
      "current time step:  995\n",
      "loss:  0.38827897237132575\n",
      "current time step:  996\n",
      "loss:  0.38827897237132575\n",
      "current time step:  997\n",
      "loss:  0.38827897237132575\n",
      "current time step:  998\n",
      "loss:  0.38827897237132575\n",
      "current time step:  999\n",
      "loss:  0.38827897237132575\n",
      "current time step:  1000\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1001\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1002\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1003\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1004\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1005\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1006\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1007\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1008\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1009\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1010\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1011\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1012\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1013\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1014\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1015\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1016\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1017\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1018\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1019\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1020\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1021\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1022\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1023\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1024\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1025\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1026\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1027\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1028\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1029\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1030\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1031\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1032\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1033\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1034\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1035\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1036\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1037\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1038\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1039\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1040\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1041\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1042\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1043\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1044\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1045\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1046\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1047\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1048\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1049\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1050\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1051\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1052\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1053\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1054\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1055\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1056\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1057\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1058\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1059\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1060\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1061\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1062\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1063\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1064\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1065\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1066\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1067\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1068\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1069\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1070\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1071\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1072\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1073\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1074\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1075\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1076\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1077\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1078\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1079\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1080\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1081\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1082\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1083\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1084\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1085\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1086\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1087\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1088\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1089\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1090\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1091\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1092\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1093\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1094\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1095\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1096\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1097\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1098\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1099\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1100\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1101\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1102\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1103\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1104\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1105\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1106\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1107\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1108\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1109\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1110\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1111\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1112\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1113\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1114\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1115\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1116\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1117\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1118\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1119\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1120\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1121\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1122\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1123\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1124\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1125\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1126\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1127\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1128\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1129\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1130\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1131\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1132\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1133\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1134\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1135\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1136\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1137\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1138\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1139\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1140\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1141\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1142\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1143\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1144\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1145\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1146\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1147\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1148\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1149\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1150\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1151\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  3.5707854100611045\n",
      "current time step:  1153\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1154\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1155\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1156\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1157\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1158\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1159\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1160\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1161\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1162\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1163\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1164\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1165\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1166\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1167\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1168\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1169\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1170\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1171\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1172\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1173\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1174\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1175\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1176\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1177\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1178\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1179\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1180\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1181\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1182\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1183\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1184\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1185\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1186\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1187\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1188\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1189\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1190\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1191\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1192\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1193\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1194\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1195\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1196\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1197\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1198\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1199\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1200\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1201\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1202\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1203\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1204\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1205\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1206\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1207\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1208\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1209\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1210\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1211\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1212\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1213\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1214\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1215\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1216\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1217\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1218\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1219\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1220\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1221\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1222\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1223\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1224\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1225\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1226\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1227\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1228\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1229\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1230\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1231\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1232\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1233\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1234\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1235\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1236\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1237\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1238\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1239\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1240\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1241\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1242\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1243\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1244\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1245\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1246\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1247\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1248\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1249\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1250\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1251\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1252\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1253\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1254\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1255\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1256\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1257\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1258\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1259\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1260\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1261\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1262\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1263\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1264\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1265\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1266\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1267\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1268\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1269\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1270\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1271\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1272\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1273\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1274\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1275\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1276\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1277\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1278\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1279\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1280\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1281\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1282\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1283\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1284\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1285\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1286\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1287\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1288\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1289\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1290\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1291\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1292\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1293\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1294\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1295\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1296\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1297\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1298\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1299\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1300\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1301\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1302\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1303\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1304\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1305\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1306\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1307\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1308\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1309\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1310\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1311\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1312\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1313\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1314\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1315\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1316\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  3.5707854100611045\n",
      "current time step:  1318\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1319\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1320\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1321\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1322\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1323\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1324\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1325\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1326\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1327\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1328\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1329\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1330\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1331\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1332\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1333\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1334\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1335\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1336\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1337\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1338\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1339\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1340\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1341\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1342\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1343\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1344\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1345\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1346\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1347\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1348\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1349\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1350\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1351\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1352\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1353\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1354\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1355\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1356\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1357\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1358\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1359\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1360\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1361\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1362\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1363\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1364\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1365\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1366\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1367\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1368\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1369\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1370\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1371\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1372\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1373\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1374\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1375\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1376\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1377\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1378\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1379\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1380\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1381\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1382\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1383\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1384\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1385\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1386\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1387\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1388\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1389\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1390\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1391\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1392\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1393\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1394\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1395\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1396\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1397\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1398\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1399\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1400\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1401\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1402\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1403\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1404\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1405\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1406\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1407\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1408\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1409\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1410\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1411\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1412\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1413\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1414\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1415\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1416\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1417\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1418\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1419\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1420\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1421\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1422\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1423\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1424\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1425\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1426\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1427\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1428\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1429\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1430\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1431\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1432\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1433\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1434\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1435\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1436\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1437\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1438\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1439\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1440\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1441\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1442\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1443\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1444\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1445\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1446\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1447\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1448\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1449\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1450\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1451\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1452\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1453\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1454\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1455\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1456\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1457\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1458\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1459\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1460\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1461\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1462\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1463\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1464\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1465\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1466\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1467\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1468\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1469\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1470\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1471\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1472\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1473\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1474\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1475\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1476\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1477\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1478\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1479\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1480\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1481\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  3.5707854100611045\n",
      "current time step:  1483\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1484\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1485\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1486\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1487\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1488\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1489\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1490\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1491\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1492\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1493\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1494\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1495\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1496\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1497\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1498\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1499\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1500\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1501\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1502\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1503\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1504\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1505\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1506\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1507\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1508\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1509\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1510\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1511\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1512\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1513\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1514\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1515\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1516\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1517\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1518\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1519\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1520\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1521\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1522\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1523\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1524\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1525\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1526\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1527\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1528\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1529\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1530\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1531\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1532\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1533\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1534\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1535\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1536\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1537\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1538\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1539\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1540\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1541\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1542\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1543\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1544\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1545\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1546\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1547\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1548\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1549\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1550\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1551\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1552\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1553\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1554\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1555\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1556\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1557\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1558\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1559\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1560\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1561\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1562\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1563\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1564\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1565\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1566\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1567\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1568\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1569\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1570\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1571\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1572\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1573\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1574\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1575\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1576\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1577\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1578\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1579\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1580\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1581\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1582\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1583\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1584\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1585\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1586\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1587\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1588\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1589\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1590\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1591\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1592\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1593\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1594\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1595\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1596\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1597\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1598\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1599\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1600\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1601\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1602\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1603\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1604\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1605\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1606\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1607\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1608\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1609\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1610\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1611\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1612\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1613\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1614\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1615\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1616\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1617\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1618\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1619\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1620\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1621\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1622\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1623\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1624\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1625\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1626\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1627\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1628\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1629\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1630\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1631\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1632\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1633\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1634\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1635\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1636\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1637\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1638\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1639\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1640\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1641\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1642\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1643\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1644\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1645\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1646\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  3.5707854100611045\n",
      "current time step:  1648\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1649\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1650\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1651\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1652\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1653\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1654\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1655\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1656\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1657\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1658\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1659\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1660\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1661\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1662\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1663\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1664\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1665\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1666\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1667\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1668\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1669\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1670\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1671\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1672\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1673\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1674\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1675\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1676\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1677\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1678\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1679\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1680\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1681\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1682\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1683\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1684\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1685\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1686\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1687\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1688\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1689\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1690\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1691\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1692\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1693\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1694\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1695\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1696\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1697\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1698\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1699\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1700\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1701\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1702\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1703\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1704\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1705\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1706\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1707\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1708\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1709\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1710\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1711\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1712\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1713\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1714\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1715\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1716\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1717\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1718\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1719\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1720\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1721\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1722\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1723\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1724\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1725\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1726\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1727\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1728\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1729\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1730\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1731\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1732\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1733\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1734\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1735\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1736\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1737\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1738\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1739\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1740\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1741\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1742\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1743\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1744\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1745\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1746\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1747\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1748\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1749\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1750\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1751\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1752\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1753\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1754\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1755\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1756\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1757\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1758\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1759\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1760\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1761\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1762\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1763\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1764\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1765\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1766\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1767\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1768\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1769\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1770\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1771\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1772\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1773\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1774\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1775\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1776\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1777\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1778\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1779\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1780\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1781\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1782\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1783\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1784\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1785\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1786\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1787\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1788\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1789\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1790\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1791\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1792\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1793\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1794\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1795\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1796\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1797\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1798\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1799\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1800\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1801\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1802\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1803\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1804\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1805\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1806\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1807\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1808\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1809\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1810\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  3.5707854100611045\n",
      "current time step:  1812\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1813\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1814\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1815\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1816\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1817\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1818\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1819\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1820\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1821\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1822\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1823\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1824\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1825\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1826\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1827\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1828\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1829\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1830\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1831\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1832\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1833\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1834\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1835\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1836\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1837\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1838\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1839\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1840\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1841\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1842\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1843\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1844\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1845\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1846\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1847\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1848\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1849\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1850\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1851\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1852\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1853\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1854\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1855\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1856\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1857\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1858\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1859\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1860\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1861\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1862\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1863\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1864\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1865\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1866\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1867\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1868\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1869\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1870\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1871\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1872\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1873\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1874\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1875\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1876\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1877\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1878\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1879\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1880\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1881\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1882\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1883\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1884\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1885\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1886\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1887\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1888\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1889\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1890\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1891\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1892\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1893\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1894\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1895\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1896\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1897\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1898\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1899\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1900\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1901\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1902\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1903\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1904\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1905\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1906\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1907\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1908\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1909\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1910\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1911\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1912\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1913\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1914\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1915\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1916\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1917\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1918\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1919\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1920\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1921\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1922\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1923\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1924\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1925\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1926\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1927\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1928\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1929\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1930\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1931\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1932\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1933\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1934\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1935\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1936\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1937\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1938\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1939\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1940\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1941\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1942\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1943\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1944\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1945\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1946\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1947\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1948\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1949\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1950\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1951\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1952\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1953\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1954\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1955\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1956\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1957\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1958\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1959\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1960\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1961\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1962\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1963\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1964\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1965\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1966\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1967\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1968\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1969\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1970\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1971\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1972\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1973\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1974\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1975\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  3.5707854100611045\n",
      "current time step:  1977\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1978\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1979\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1980\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1981\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1982\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1983\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1984\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1985\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1986\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1987\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1988\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1989\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1990\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1991\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1992\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1993\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1994\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1995\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1996\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1997\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1998\n",
      "loss:  3.5707854100611045\n",
      "current time step:  1999\n",
      "loss:  3.5707854100611045\n"
     ]
    }
   ],
   "source": [
    "linear_opt_control_mass, linear_kdv_opt_mass_soln = KoopmanMPC(y0=y0_track,\n",
    "                                                traj_len=traj_len_track,\n",
    "                                                soln_ref=mass_ref, \n",
    "                                                kdv_solver=kdv_solution,\n",
    "                                                B=B_mass,\n",
    "                                                loss=mpc_loss_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(os.path.join(data_path,'no_penalty_linear_mass_kdv_opt_control_20s_greedy.csv'), linear_opt_control_mass, delimiter=',')\n",
    "# np.savetxt(os.path.join(data_path,'no_penalty_linear_mass_kdv_opt_soln_20s_greedy.csv'), linear_kdv_opt_mass_soln, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_opt_control_mass = np.loadtxt(os.path.join(data_path,'linear_mass_kdv_opt_control_20s_greedy.csv'), delimiter=',')\n",
    "# linear_kdv_opt_mass_soln = np.loadtxt(os.path.join(data_path,'linear_mass_kdv_opt_soln_20s_greedy.csv'), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_kdv_opt_mass = dx * tf.reduce_sum(linear_kdv_opt_mass_soln, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fcb5836ca60>"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mass_ref, label='reference')\n",
    "plt.plot(linear_kdv_opt_mass, label='linear')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcb584146a0>]"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(linear_opt_control_mass[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2, 0.2, 0.2, ..., 0.2, 0.2, 0.2],\n",
       "       [0.2, 0.2, 0.2, ..., 0.2, 0.2, 0.2],\n",
       "       [0.2, 0.2, 0.2, ..., 0.2, 0.2, 0.2],\n",
       "       ...,\n",
       "       [0.2, 0.2, 0.2, ..., 0.2, 0.2, 0.2],\n",
       "       [0.2, 0.2, 0.2, ..., 0.2, 0.2, 0.2],\n",
       "       [0.2, 0.2, 0.2, ..., 0.2, 0.2, 0.2]])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_kdv_opt_mass_soln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_pred_opt_control = compute_linear_obs(y0_track, linear_opt_control_mass, B_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fcb5755f6d0>"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(linear_pred_opt_control, label='test')\n",
    "plt.plot(mass_ref, label='reference')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.26653184,  1.27669492,  1.28685768, ..., 21.22432485,\n",
       "       21.23423771, 21.24414957])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx*linear_pred_opt_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "       0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "       0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "       0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "       0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "       0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "       0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "       0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "       0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "       0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96358"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0102"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controllability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample control\n",
    "np.random.seed(seed=111)\n",
    "n_control_samples = 2000\n",
    "control_samples = np.random.uniform(low=0, high=1, size=(n_control_samples, param_dim)) * (umax - umin) + umin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_bu = solver_linear.model.get_layer('Layer_B')(control_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Layer_B/kernel:0' shape=(3, 4) dtype=float64, numpy=\n",
       " array([[-1.30104261e-17,  6.84490017e-02, -7.48895866e-04,\n",
       "          2.08050131e-04],\n",
       "        [-9.25908655e-17,  6.86751627e-02, -5.40985905e-04,\n",
       "          3.15769172e-04],\n",
       "        [-3.45535232e-16,  6.86216604e-02, -8.40655009e-04,\n",
       "          3.86985534e-04]])>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver_linear.model.get_layer('Layer_B').weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 3)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_bu = tf.reshape(vector_bu, shape=(vector_bu.shape[0],n_psi,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_zeros = tf.zeros(shape=(vector_bu.shape[0], n_psi, n_psi-1), dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_bu = tf.concat([vector_bu, vector_zeros], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float64, numpy=\n",
       "array([[ 1.02551195e-16,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [-3.88729764e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 2.97554246e-04,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [-2.11809569e-04,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00]])>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_bu[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3x3 identity matrix\n",
    "identity_matrix = np.eye(n_psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_A = solver_linear.model.get_layer('Layer_A')(identity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float64, numpy=\n",
       "array([[ 1.00000000e+00,  1.09276740e-03, -1.49643422e-03,\n",
       "         9.23807438e-04],\n",
       "       [-9.80118764e-17,  9.99806932e-01, -6.53436978e-05,\n",
       "        -4.74398849e-05],\n",
       "       [-2.22044605e-16, -6.21362578e-03,  1.00227680e+00,\n",
       "        -3.83239310e-03],\n",
       "       [ 4.99600361e-15,  2.24902565e-02,  2.11449817e-02,\n",
       "         1.00015566e+00]])>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_K_matrix = matrix_bu + matrix_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_A_matrix = (linear_K_matrix - identity_matrix) / T\n",
    "\n",
    "linear_A_vector = tf.reshape(linear_A_matrix, shape=(linear_A_matrix.shape[0], linear_A_matrix.shape[-1]*linear_A_matrix.shape[-1]))\n",
    "\n",
    "rank = np.linalg.matrix_rank(linear_A_vector)\n",
    "\n",
    "U, S, VT = np.linalg.svd(linear_A_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(S > 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.00907567e+02, 1.42514091e+02, 5.66001169e-01, 3.23417390e-01,\n",
       "       6.93493129e-13, 2.87072870e-13, 4.13389705e-15, 1.04323524e-17,\n",
       "       9.59488603e-18, 2.66896110e-18, 1.23800720e-18, 4.75004906e-19,\n",
       "       1.53639253e-19, 7.46375738e-22, 1.18486091e-29, 7.99100638e-34])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.32550612e+02, 4.32186938e+01, 1.64202796e+00, 3.39976981e-01])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the rank of psi_y\n",
    "\n",
    "psi_x = dic_linear(data_x[:2000,:])\n",
    "\n",
    "U_x, S_x, VT_x = np.linalg.svd(psi_x.numpy())\n",
    "\n",
    "S_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_linear.model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "koopman",
   "language": "python",
   "name": "koopman"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
