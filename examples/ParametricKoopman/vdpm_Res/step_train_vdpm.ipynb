{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from koopmanlib.dictionary import PsiNN\n",
    "from koopmanlib.param_solver import (\n",
    "    KoopmanBilinearDLSolver,\n",
    "    KoopmanLinearDLSolver,\n",
    "    KoopmanParametricDLSolver,\n",
    ")\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"config_vdpm.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_file = sys.argv[1]\n",
    "with open(config_file, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "data_path = config[\"data_settings\"][\"data_path\"]\n",
    "weights_path = config[\"nn_settings\"][\"weights_path\"]\n",
    "\n",
    "n_psi_train = config[\"nn_settings\"][\"n_psi_train\"]\n",
    "mu_list = config[\"data_settings\"][\"mu\"]\n",
    "\n",
    "\n",
    "target_dim = 2\n",
    "param_dim = 1\n",
    "\n",
    "n_psi = 1 + target_dim + n_psi_train\n",
    "\n",
    "dict_layer_size = config[\"nn_settings\"][\"dict_layer_size\"]\n",
    "K_layer_size_list = config[\"nn_settings\"][\"K_layer_size\"]\n",
    "\n",
    "linear_epochs = config[\"nn_settings\"][\"linear_epochs\"]\n",
    "bilinear_epochs = config[\"nn_settings\"][\"bilinear_epochs\"]\n",
    "pknn_epochs = config[\"nn_settings\"][\"pknn_epochs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_layer_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomLoss(tf.keras.losses.Loss):\n",
    "#     def __init__(self, time_step, **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.time_step = time_step\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "\n",
    "#         # # mse loss on psi\n",
    "#         # mse = tf.reduce_mean(tf.square(tf.norm(psi_next-psi_y, axis=-1))) / (self.time_step)**2\n",
    "\n",
    "#         # mse loss on psi\n",
    "#         self.mse = tf.square(tf.norm(y_true-y_pred, axis=-1)) / (self.time_step**2)\n",
    "#         return self.mse\n",
    "\n",
    "# my_loss = CustomLoss(time_step=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = mu_list[0]\n",
    "K_layer_size = K_layer_size_list[0]\n",
    "\n",
    "# Load data\n",
    "dict_data = np.load(os.path.join(data_path, \"vdpm_data_mu_\" + str(mu) + \".npy\"), allow_pickle=True)\n",
    "\n",
    "data_x = dict_data[()][\"data_x\"]\n",
    "data_y = dict_data[()][\"data_y\"]\n",
    "data_u = dict_data[()][\"data_u\"]\n",
    "\n",
    "# PK-NN\n",
    "dic_pk = PsiNN(layer_sizes=dict_layer_size, n_psi_train=n_psi_train, name=\"psi_nn_layer\")\n",
    "from koopmanlib.K_structure import Model_K_u_Layer, Model_K_u_Layer_One\n",
    "\n",
    "model_K_u = Model_K_u_Layer_One(layer_sizes=K_layer_size, n_psi=n_psi, activation=\"tanh\")\n",
    "\n",
    "solver_pk = KoopmanParametricDLSolver(\n",
    "    target_dim=target_dim, param_dim=param_dim, n_psi=n_psi, dic=dic_pk, model_K_u=model_K_u\n",
    ")\n",
    "\n",
    "model_pk, model_K_u_pred_pk = solver_pk.generate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_data_y_train = tf.zeros_like(dic_pk(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "opt = Adam(lr)\n",
    "\n",
    "model_pk.compile(optimizer=opt, loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_callbacks = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"loss\",\n",
    "    factor=0.1,\n",
    "    patience=100,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    min_delta=1e-4,\n",
    "    cooldown=0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "# Define the early stopping criteria\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=1e-9, patience=50, verbose=1, mode=\"auto\"\n",
    ")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(weights_path, \"model_pk_vdpm_mu_\" + str(mu) + \".h5\"),\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=\"min\",\n",
    "    save_freq=\"epoch\",\n",
    ")\n",
    "\n",
    "# Add early_stopping to the list of callbacks\n",
    "callbacks = [lr_callbacks, es_callback, checkpoint_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_pk.fit(\n",
    "    x=[data_x, data_y, data_u],\n",
    "    y=zeros_data_y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=pknn_epochs,\n",
    "    batch_size=200,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pk.save_weights(os.path.join(\n",
    "#         weights_path, 'model_pk_vdpm_mu_'+str(mu)+'.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pk.get_layer('DicNN').trainable = False\n",
    "# for layer in solver_pk.model_K_u.hidden_layers:\n",
    "#     layer.trainable = False\n",
    "# solver_pk.model_K_u.output_layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pk.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pk.compile(optimizer=Adam(lr=1e-4),\n",
    "#                     loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model_pk.fit(x=[data_x, data_y, data_u],\n",
    "#                     y=zeros_data_y_train,\n",
    "#                     validation_split=0.2,\n",
    "#                     epochs=100,\n",
    "#                     batch_size=200,\n",
    "#                     callbacks=lr_callbacks,\n",
    "#                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pk.save_weights(os.path.join(\n",
    "#         weights_path, 'train_dense_model_pk_vdpm_mu_'+str(mu)+'.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 1e-5\n",
    "\n",
    "# opt = Adam(lr)\n",
    "# model_pk.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "# # lr_callbacks = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss',\n",
    "# #                                                     factor=0.1,\n",
    "# #                                                     patience=200,\n",
    "# #                                                     verbose=0,\n",
    "# #                                                     mode='auto',\n",
    "# #                                                     min_delta=0.0001,\n",
    "# #                                                     cooldown=0,\n",
    "# #                                                     min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_interval = 20\n",
    "# lr_decay_factor = 0.8\n",
    "# from tqdm.keras import TqdmCallback\n",
    "\n",
    "# losses = []\n",
    "# for i in range(100):\n",
    "#     print('number of the outer loop:', i)\n",
    "\n",
    "#     model_pk.get_layer('K_u_pred').trainable = False\n",
    "#     model_pk.get_layer('DicNN').trainable = True\n",
    "\n",
    "#     history_dic = model_pk.fit(x=[data_x, data_y, data_u],\n",
    "#                     y=zeros_data_y_train,\n",
    "#                     epochs=20,\n",
    "#                     batch_size=200,\n",
    "#                     callbacks=TqdmCallback(verbose=1),\n",
    "#                     verbose=0)\n",
    "\n",
    "#     model_pk.get_layer('K_u_pred').trainable = True\n",
    "#     model_pk.get_layer('DicNN').trainable = False\n",
    "\n",
    "#     history_K_u = model_pk.fit(x=[data_x, data_y, data_u],\n",
    "#                     y=zeros_data_y_train,\n",
    "#                     epochs=100,\n",
    "#                     batch_size=200,\n",
    "#                     callbacks=TqdmCallback(verbose=1),\n",
    "#                     verbose=0)\n",
    "\n",
    "#     if i % log_interval == 0:\n",
    "#         losses.append(history_K_u.history['loss'][-1])\n",
    "\n",
    "#         # Adjust learning rate:\n",
    "#         if len(losses) > 2:\n",
    "#             if losses[-1] > losses[-2]:\n",
    "#                 print(\"Error increased. Decay learning rate\")\n",
    "#                 curr_lr = lr_decay_factor * model_pk.optimizer.lr\n",
    "#                 model_pk.optimizer.lr = curr_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pk.save_weights(os.path.join(\n",
    "#     weights_path, 'test_model_pk_vdpm_mu_'+str(mu)+'.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Model: Dynamics is $Az +Bu$\n",
    "\n",
    "dic_linear = PsiNN(layer_sizes=dict_layer_size, n_psi_train=n_psi_train)\n",
    "\n",
    "solver_linear = KoopmanLinearDLSolver(\n",
    "    dic=dic_linear, target_dim=target_dim, param_dim=param_dim, n_psi=n_psi\n",
    ")\n",
    "\n",
    "model_linear = solver_linear.build_model()\n",
    "\n",
    "solver_linear.build(\n",
    "    model_linear,\n",
    "    data_x,\n",
    "    data_u,\n",
    "    data_y,\n",
    "    zeros_data_y_train,\n",
    "    epochs=linear_epochs,\n",
    "    batch_size=200,\n",
    "    lr=0.0001,\n",
    "    lr_patience=100,\n",
    "    lr_decay_factor=0.1,\n",
    "    lr_min=1e-6,\n",
    "    es_patience=50,\n",
    "    es_min_delta=1e-9,\n",
    "    filepath=os.path.join(weights_path, \"model_linear_vdpm_mu_\" + str(mu) + \".h5\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bilinear Model: Dynamics is $Az + \\sum_{i=1}^{N_{u}}B_{i}zu_{i}$\n",
    "\n",
    "dic_bilinear = PsiNN(layer_sizes=dict_layer_size, n_psi_train=n_psi_train)\n",
    "\n",
    "solver_bilinear = KoopmanBilinearDLSolver(\n",
    "    dic=dic_bilinear, target_dim=target_dim, param_dim=param_dim, n_psi=n_psi\n",
    ")\n",
    "\n",
    "model_bilinear = solver_bilinear.build_model()\n",
    "\n",
    "solver_bilinear.build(\n",
    "    model_bilinear,\n",
    "    data_x,\n",
    "    data_u,\n",
    "    data_y,\n",
    "    zeros_data_y_train,\n",
    "    epochs=bilinear_epochs,\n",
    "    batch_size=200,\n",
    "    lr=0.0001,\n",
    "    lr_patience=100,\n",
    "    lr_decay_factor=0.1,\n",
    "    lr_min=1e-6,\n",
    "    es_patience=50,\n",
    "    es_min_delta=1e-9,\n",
    "    filepath=os.path.join(weights_path, \"model_bilinear_vdpm_mu_\" + str(mu) + \".h5\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mu, K_layer_size in zip(mu_list, K_layer_size_list):\n",
    "#     load_data_and_train_models(mu, K_layer_size)\n",
    "#     print('mu = ', mu, 'done')\n",
    "#     print('K_layer_size = ', K_layer_size, 'done')\n",
    "\n",
    "# load_data_and_train_models(mu=mu_list[0], K_layer_size=K_layer_size_list[0])\n",
    "# print('mu = ', mu_list[0], 'done')\n",
    "# print('K_layer_size = ', K_layer_size_list[0], 'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data_and_train_models(mu, K_layer_size):\n",
    "\n",
    "#     # Load data\n",
    "#     dict_data = np.load(os.path.join(\n",
    "#         data_path, 'vdpm_data_mu_'+str(mu)+'.npy'), allow_pickle=True)\n",
    "\n",
    "#     data_x = dict_data[()]['data_x']\n",
    "#     data_y = dict_data[()]['data_y']\n",
    "#     data_u = dict_data[()]['data_u']\n",
    "\n",
    "#     # PK-NN\n",
    "#     dic_pk = PsiNN(layer_sizes=dict_layer_size, n_psi_train=n_psi_train)\n",
    "#     from koopmanlib.K_structure import Model_K_u_Layer, Model_K_u_Layer_One\n",
    "\n",
    "#     model_K_u = Model_K_u_Layer_One(layer_sizes=K_layer_size,\n",
    "#                                     n_psi=n_psi,\n",
    "#                                     activation='tanh')\n",
    "\n",
    "#     solver_pk = KoopmanParametricDLSolver(\n",
    "#         target_dim=target_dim,\n",
    "#         param_dim=param_dim,\n",
    "#         n_psi=n_psi,\n",
    "#         dic=dic_pk,\n",
    "#         model_K_u=model_K_u)\n",
    "\n",
    "#     model_pk, model_K_u_pred_pk = solver_pk.generate_model()\n",
    "\n",
    "#     model_pk.summary()\n",
    "\n",
    "#     zeros_data_y_train = tf.zeros_like(dic_pk(data_y))\n",
    "\n",
    "#     model_pk.compile(optimizer=Adam(0.001),\n",
    "#                     loss='mse')\n",
    "\n",
    "#     # model_pk.compile(optimizer=Adam(0.001),\n",
    "#     #                 loss=my_loss)\n",
    "\n",
    "#     lr_callbacks = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss',\n",
    "#                                                         factor=0.1,\n",
    "#                                                         patience=200,\n",
    "#                                                         verbose=0,\n",
    "#                                                         mode='auto',\n",
    "#                                                         min_delta=0.0001,\n",
    "#                                                         cooldown=0,\n",
    "#                                                         min_lr=1e-6)\n",
    "\n",
    "#     history = model_pk.fit(x=[data_x, data_y, data_u],\n",
    "#                         y=zeros_data_y_train,\n",
    "#                         epochs=pknn_epochs,\n",
    "#                         batch_size=200,\n",
    "#                         callbacks=lr_callbacks,\n",
    "#                         verbose=1)\n",
    "\n",
    "\n",
    "#     model_pk.save_weights(os.path.join(\n",
    "#         weights_path, 'model_pk_vdpm_mu_'+str(mu)+'.h5'))\n",
    "\n",
    "#     # # Linear Model: Dynamics is $Az +Bu$\n",
    "\n",
    "#     # dic_linear = PsiNN(layer_sizes=dict_layer_size, n_psi_train=n_psi_train)\n",
    "\n",
    "#     # solver_linear = KoopmanLinearDLSolver(\n",
    "#     #     dic=dic_linear, target_dim=target_dim, param_dim=param_dim, n_psi=n_psi)\n",
    "\n",
    "#     # model_linear = solver_linear.build_model()\n",
    "\n",
    "#     # solver_linear.build(model_linear,\n",
    "#     #                     data_x,\n",
    "#     #                     data_u,\n",
    "#     #                     data_y,\n",
    "#     #                     zeros_data_y_train,\n",
    "#     #                     epochs=linear_epochs,\n",
    "#     #                     batch_size=200,\n",
    "#     #                     lr=0.0001,\n",
    "#     #                     log_interval=20,\n",
    "#     #                     lr_decay_factor=0.1)\n",
    "\n",
    "#     # model_linear.save_weights(os.path.join(\n",
    "#     #     weights_path, 'model_linear_vdpm_mu_'+str(mu)+'.h5'))\n",
    "\n",
    "\n",
    "#     # # Bilinear Model: Dynamics is $Az + \\sum_{i=1}^{N_{u}}B_{i}zu_{i}$\n",
    "\n",
    "#     # dic_bilinear = PsiNN(layer_sizes=dict_layer_size, n_psi_train=n_psi_train)\n",
    "\n",
    "#     # solver_bilinear = KoopmanBilinearDLSolver(\n",
    "#     #     dic=dic_bilinear, target_dim=target_dim, param_dim=param_dim, n_psi=n_psi)\n",
    "\n",
    "#     # model_bilinear = solver_bilinear.build_model()\n",
    "\n",
    "#     # solver_bilinear.build(model_bilinear,\n",
    "#     #                       data_x,\n",
    "#     #                       data_u,\n",
    "#     #                       data_y,\n",
    "#     #                       zeros_data_y_train,\n",
    "#     #                       epochs=linear_epochs,\n",
    "#     #                       batch_size=200,\n",
    "#     #                       lr=0.0001,\n",
    "#     #                       log_interval=20,\n",
    "#     #                       lr_decay_factor=0.1)\n",
    "\n",
    "#     # model_bilinear.save_weights(os.path.join(\n",
    "#     #     weights_path, 'model_bilinear_vdpm_mu_'+str(mu)+'.h5'))\n",
    "\n",
    "# # for mu, K_layer_size in zip(mu_list, K_layer_size_list):\n",
    "# #     load_data_and_train_models(mu, K_layer_size)\n",
    "# #     print('mu = ', mu, 'done')\n",
    "# #     print('K_layer_size = ', K_layer_size, 'done')\n",
    "\n",
    "# load_data_and_train_models(mu=mu_list[0], K_layer_size=K_layer_size_list[0])\n",
    "# print('mu = ', mu_list[0], 'done')\n",
    "# print('K_layer_size = ', K_layer_size_list[0], 'done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pknn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
